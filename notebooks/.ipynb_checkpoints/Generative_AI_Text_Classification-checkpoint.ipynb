{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1224ff1-aeff-4e29-b202-481832e55ab0",
   "metadata": {},
   "source": [
    "# Generative AI Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "882e6f12-da61-4f0b-ab64-3526080a77b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import opendatasets as od\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import s3fs\n",
    "import fs_s3fs\n",
    "import fsspec\n",
    "import json\n",
    "from llama_index.core import TreeIndex, SimpleDirectoryReader\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import transformers\n",
    "import mlflow\n",
    "import hyperopt as hp\n",
    "import sphinx\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2fbad013-ca4e-4666-9764-f040416cb0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download stopwords\n",
    "\n",
    "#nltk.download('stopwords')\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "newStopwords = ['b','lt','gt','n','u','ap','reuters'] # Add stopwords \n",
    "\n",
    "for stopword in newStopwords:\n",
    "    stopwords.append(stopword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43282ff1-8419-4736-86e3-cfd2c3a008d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762117e8-eeaf-45ea-98d6-4bbfca6447d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648def37-b389-46cd-a7d8-a0344a83439a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dataset from Kaggle\n",
    "\n",
    "dataset = \"https://www.kaggle.com/datasets/amananandrai/ag-news-classification-dataset/data\"\n",
    "od.download(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2f5b57f-b8de-46d5-a7fd-f5de9f7b5573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read dataset, import only 30000 rows of data\n",
    "df = pd.read_csv(r'C:\\Users\\nickr\\OneDrive\\Documents\\GitHub\\generative-ai-text-summarization\\data\\ag-news-classification-dataset\\ag_news.csv',nrows=30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24ceb048-4a45-4b4e-ad52-44b5918d6dd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check shape of dataframe\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7925624a-4c1d-4927-808f-5975d06b0384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class Index</th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Wall St. Bears Claw Back Into the Black (Reuters)</td>\n",
       "      <td>Reuters - Short-sellers, Wall Street's dwindli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n",
       "      <td>Reuters - Private investment firm Carlyle Grou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Oil and Economy Cloud Stocks' Outlook (Reuters)</td>\n",
       "      <td>Reuters - Soaring crude prices plus worries\\ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Iraq Halts Oil Exports from Main Southern Pipe...</td>\n",
       "      <td>Reuters - Authorities have halted oil export\\f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Oil prices soar to all-time record, posing new...</td>\n",
       "      <td>AFP - Tearaway world oil prices, toppling reco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>Stocks End Up, But Near Year Lows (Reuters)</td>\n",
       "      <td>Reuters - Stocks ended slightly higher on Frid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>Money Funds Fell in Latest Week (AP)</td>\n",
       "      <td>AP - Assets of the nation's retail money marke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>Fed minutes show dissent over inflation (USATO...</td>\n",
       "      <td>USATODAY.com - Retail sales bounced back a bit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class Index                                              Title  \\\n",
       "0            3  Wall St. Bears Claw Back Into the Black (Reuters)   \n",
       "1            3  Carlyle Looks Toward Commercial Aerospace (Reu...   \n",
       "2            3    Oil and Economy Cloud Stocks' Outlook (Reuters)   \n",
       "3            3  Iraq Halts Oil Exports from Main Southern Pipe...   \n",
       "4            3  Oil prices soar to all-time record, posing new...   \n",
       "5            3        Stocks End Up, But Near Year Lows (Reuters)   \n",
       "6            3               Money Funds Fell in Latest Week (AP)   \n",
       "7            3  Fed minutes show dissent over inflation (USATO...   \n",
       "\n",
       "                                         Description  \n",
       "0  Reuters - Short-sellers, Wall Street's dwindli...  \n",
       "1  Reuters - Private investment firm Carlyle Grou...  \n",
       "2  Reuters - Soaring crude prices plus worries\\ab...  \n",
       "3  Reuters - Authorities have halted oil export\\f...  \n",
       "4  AFP - Tearaway world oil prices, toppling reco...  \n",
       "5  Reuters - Stocks ended slightly higher on Frid...  \n",
       "6  AP - Assets of the nation's retail money marke...  \n",
       "7  USATODAY.com - Retail sales bounced back a bit...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirm importation\n",
    "\n",
    "df.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ab63fb0-1213-4f55-b10d-3b0c409af02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Description column\n",
    "\n",
    "df = df.drop('Description',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53803b54-f203-406b-9cfc-3931fa943371",
   "metadata": {},
   "source": [
    "# Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d737225c-a1f0-4109-abde-5c2d75506d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find null values and datatypes\n",
    "\n",
    "df.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be72a3e-3d19-4901-abdb-7fa1006122fb",
   "metadata": {},
   "source": [
    "There are no null values in the df_train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6816ed8-6b16-4f5a-8e8f-86c6745b22ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for duplicates\n",
    "\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8028175-62cd-4820-a191-1e6ae3652326",
   "metadata": {},
   "source": [
    "There are no duplicate values in the df_train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1fc8c488-1f0f-4f07-bf1a-93b1e604194e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning data set html, special, and non-textual characters\n",
    "\n",
    "def cleaning_text(text):\n",
    "    # Remove HTML tags\n",
    "    cleaning_text = re.sub('<.*?>', '', text)\n",
    "    # Remove special characters and non-textual \n",
    "    cleaning_text = re.sub(r'([^a-zA-Z\\s]|\\\\b[A-Za-z] \\\\b|\\\\b [A-Za-z]\\\\b)', ' ', cleaning_text) # checks plain text for given characters\n",
    "    return cleaning_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1479d5c2-b4e2-4c30-9faf-3051b423d117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply text cleaning to text in both Description and Title\n",
    "\n",
    "df['Title'] = df['Title'].apply(cleaning_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fa5a1d06-2735-4db7-86ec-acc992362765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class Index</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Wall St  Bears Claw Back Into the Black  Reuters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Carlyle Looks Toward Commercial Aerospace  Reu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Oil and Economy Cloud Stocks  Outlook  Reuters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Iraq Halts Oil Exports from Main Southern Pipe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Oil prices soar to all time record  posing new...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>Stocks End Up  But Near Year Lows  Reuters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>Money Funds Fell in Latest Week  AP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class Index                                              Title\n",
       "0            3  Wall St  Bears Claw Back Into the Black  Reuters \n",
       "1            3  Carlyle Looks Toward Commercial Aerospace  Reu...\n",
       "2            3    Oil and Economy Cloud Stocks  Outlook  Reuters \n",
       "3            3  Iraq Halts Oil Exports from Main Southern Pipe...\n",
       "4            3  Oil prices soar to all time record  posing new...\n",
       "5            3        Stocks End Up  But Near Year Lows  Reuters \n",
       "6            3               Money Funds Fell in Latest Week  AP "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that the function worked\n",
    "\n",
    "df.head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518814df-08e0-40e6-8b97-f87cbc98e8e9",
   "metadata": {},
   "source": [
    "Note that in this data set, 1 represents World News, 2 represents Sports News, 3 represents Business News, and 4 represents Sci/Tech news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0223382e-0fd0-4e2a-a2ce-58bf02a2b5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to remove stop words\n",
    "\n",
    "stop_words = set(stopwords)\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text.lower())  # Tokenization and lowercasing\n",
    "    tokens = [word for word in tokens if word not in stop_words]  # Stop word removal\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "904e8790-b96c-4391-96c5-1ceb2209ee41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply preprocessing to text in Title\n",
    "\n",
    "df['Title'] = df['Title'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85872e09-1b0f-4991-9337-10ffec72a040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that the function worked\n",
    "\n",
    "df.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e870c4d-abfd-4af9-b3e3-200b57aea54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to CSV for ease of use in future\n",
    "\n",
    "cleaned_data_file = r'C:\\Users\\nickr\\OneDrive\\Desktop\\CapstoneTechX\\ag_news_cleaned\\cleaned_ag_news.csv'\n",
    "df.to_csv(cleaned_data_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51cd8cdb-add6-4426-84db-803400bbc1f3",
   "metadata": {},
   "source": [
    "# Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "55d4286e-9003-4783-b52f-b2a3754fbd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training data into training and validation data \n",
    "\n",
    "df_train, df_test = train_test_split(df, test_size=.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d183cea1-30ce-46b1-9a88-60e5a0dcb957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create csv file for train and test data\n",
    "\n",
    "df_train.to_csv(os.path.join(r'C:\\Users\\nickr\\OneDrive\\Desktop\\CapstoneTechX\\ag_news_cleaned', 'train.csv'), index=False)\n",
    "df_test.to_csv(os.path.join(r'C:\\Users\\nickr\\OneDrive\\Desktop\\CapstoneTechX\\ag_news_cleaned', 'test.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcfdf86-2d73-4a16-83bf-292849e06163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature data directory\n",
    "\n",
    "feature_data_dir = r'C:\\Users\\nickr\\OneDrive\\Desktop\\CapstoneTechX\\features'\n",
    "os.makedirs(feature_data_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "75d65b5e-2da9-43bf-a4ee-12528882de24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF Vectorization for Title\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=3000)  # we can play around with this. This was an arbitrary value\n",
    "train_title_features = tfidf_vectorizer.fit_transform(df_train['Title'])\n",
    "test_title_features = tfidf_vectorizer.transform(df_test['Title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7305e5a-8503-47ef-9a90-d9111b0a741b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at one of the matrices the vectorizer produces\n",
    "\n",
    "# print(df_train['Title'][98])\n",
    "# print(train_title_features.toarray()[98]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c8896a-912f-4ae6-93e7-bcc49eb426ac",
   "metadata": {},
   "source": [
    "Note, the vectorizer produces a value for a specific word on a scale of 0 to 1. The closer the number is to 1, the more unique that word is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "371fd926-9565-407d-b609-d86be6844fc8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tennis': 2659, 'agassi': 38, 'goes': 1114, 'google': 1122, 'still': 2535, 'last': 1456, 'digital': 720, 'radio': 2082, 'new': 1736, 'front': 1055, 'piracy': 1912, 'war': 2891, 'sony': 2463, 'group': 1142, 'agrees': 45, 'buy': 354, 'mgm': 1619, 'toys': 2730, 'wireless': 2945, 'crowd': 611, 'join': 1386, 'nikkei': 1748, 'average': 178, 'update': 2809, 'nd': 1718, 'shows': 2393, 'request': 2168, 'issue': 1358, 'drops': 782, 'israel': 1355, 'build': 344, 'housing': 1252, 'units': 2803, 'profits': 2022, 'rise': 2207, 'retail': 2182, 'un': 2794, 'staff': 2505, 'call': 365, 'afghan': 32, 'pullout': 2044, 'singh': 2414, 'could': 580, 'woods': 2956, 'chechen': 445, 'story': 2546, 'leader': 1474, 'terror': 2663, 'russia': 2250, 'woodward': 2957, 'lions': 1513, 'coach': 504, 'internet': 1330, 'turns': 2780, 'work': 2959, 'progress': 2025, 'taken': 2625, 'along': 71, 'issues': 1359, 'finally': 966, 'comes': 521, 'age': 39, 'athens': 156, 'van': 2835, 'continues': 561, 'cassini': 406, 'discovers': 731, 'two': 2785, 'moons': 1668, 'scientists': 2294, 'study': 2565, 'effects': 817, 'cruise': 615, 'ship': 2381, 'waste': 2903, 'palestinian': 1841, 'militants': 1632, 'killed': 1422, 'gaza': 1081, 'fda': 940, 'oks': 1786, 'version': 2844, 'investors': 1339, 'see': 2318, 'eagles': 794, 'super': 2587, 'bowl': 303, 'germany': 1093, 'asks': 147, 'protest': 2036, 'central': 420, 'park': 1847, 'gold': 1116, 'phelps': 1892, 'relay': 2149, 'team': 2642, 'falters': 923, 'partner': 1852, 'charges': 440, 'riaa': 2201, 'patent': 1862, 'opec': 1792, 'limited': 1503, 'ahead': 46, 'wednesday': 2919, 'meet': 1600, 'red': 2132, 'planet': 1920, 'life': 1496, 'blue': 277, 'death': 657, 'city': 474, 'calm': 370, 'bloody': 274, 'governor': 1126, 'protests': 2038, 'olympic': 1788, 'lee': 1485, 'wins': 2944, 'case': 403, 'vs': 2878, 'porn': 1964, 'site': 2418, 'critical': 606, 'agreement': 44, 'boeing': 283, 'makes': 1559, 'hurdles': 1268, 'comeback': 520, 'firms': 985, 'post': 1968, 'drug': 784, 'data': 644, 'murder': 1695, 'killing': 1424, 'electronic': 830, 'net': 1729, 'olympics': 1789, 'cink': 467, 'eases': 802, 'four': 1038, 'shot': 2389, 'win': 2938, 'nec': 1722, 'invitational': 1340, 'volkswagen': 2869, 'mexican': 1617, 'workers': 2960, 'accept': 5, 'pay': 1867, 'increase': 1296, 'says': 2278, 'apple': 112, 'unveils': 2807, 'imac': 1285, 'worst': 2968, 'pass': 1857, 'us': 2823, 'crisis': 605, 'darfur': 643, 'bank': 199, 'canada': 375, 'leaves': 1481, 'interest': 1327, 'rates': 2102, 'cisco': 470, 'acquire': 13, 'network': 1733, 'disney': 737, 'ceo': 422, 'leave': 1480, 'review': 2194, 'campaign': 374, 'finance': 968, 'web': 2916, 'sites': 2419, 'huge': 1260, 'kills': 1426, 'one': 1790, 'injures': 1313, 'six': 2421, 'others': 1814, 'canadian': 376, 'press': 1990, 'lab': 1442, 'finds': 972, 'deadly': 654, 'virus': 2861, 'pigs': 1905, 'china': 460, 'helicopter': 1199, 'stunt': 2568, 'pilots': 1907, 'nasa': 1710, 'ibm': 1274, 'buys': 357, 'content': 557, 'integration': 1322, 'talks': 2633, 'resume': 2180, 'airline': 56, 'israeli': 1356, 'cabinet': 360, 'approves': 121, 'settlers': 2362, 'russian': 2251, 'astronauts': 153, 'mission': 1650, 'ebay': 806, 'stake': 2507, 'disaster': 727, 'officials': 1782, 'get': 1095, 'ready': 2116, 'patch': 1860, 'enron': 846, 'high': 1208, 'blackburn': 261, 'names': 1708, 'hughes': 1261, 'free': 1045, 'code': 508, 'stocks': 2537, 'move': 1683, 'higher': 1209, 'oil': 1784, 'prices': 1994, 'decline': 666, 'ex': 878, 'gets': 1096, 'sentence': 2343, 'chips': 463, 'hurt': 1271, 'alcoa': 62, 'techs': 2648, 'aol': 106, 'launches': 1463, 'pc': 1872, 'line': 1505, 'typhoon': 2786, 'aere': 31, 'pounds': 1975, 'taiwan': 2623, 'heads': 1189, 'monday': 1661, 'features': 944, 'art': 141, 'hits': 1221, 'th': 2673, 'hr': 1257, 'reds': 2133, 'beat': 223, 'backs': 189, 'gatlin': 1080, 'gun': 1156, 'fastest': 933, 'historic': 1217, 'closes': 497, 'south': 2471, 'korean': 1435, 'auction': 167, 'house': 1251, 'giants': 1101, 'give': 1104, 'first': 986, 'start': 2517, 'thursday': 2692, 'edwards': 815, 'bush': 350, 'lay': 1470, 'arsenal': 140, 'exit': 885, 'would': 2970, 'people': 1882, 'british': 326, 'soldier': 2456, 'faces': 910, 'charge': 437, 'iraqi': 1348, 'man': 1563, 'offering': 1777, 'sec': 2311, 'approval': 119, 'equatorial': 855, 'guinea': 1154, 'suspends': 2601, 'coup': 586, 'trial': 2749, 'schumacher': 2289, 'ferrari': 952, 'seals': 2304, 'formula': 1034, 'title': 2706, 'takes': 2628, 'prime': 1998, 'st': 2504, 'gives': 1106, 'cards': 396, 'lead': 1473, 'prize': 2007, 'long': 1524, 'shots': 2390, 'play': 1928, 'lexmark': 1494, 'dell': 682, 'printers': 2000, 'shock': 2384, 'hazard': 1185, 'home': 1234, 'sales': 2263, 'fall': 918, 'july': 1399, 'tyson': 2787, 'cuts': 631, 'forecast': 1026, 'costs': 579, 'arctic': 126, 'science': 2291, 'cold': 511, 'style': 2569, 'hungary': 1265, 'breaks': 316, 'record': 2129, 'elects': 832, 'al': 60, 'president': 1988, 'citigroup': 473, 'american': 78, 'sees': 2324, 'much': 1692, 'meets': 1603, 'eye': 907, 'end': 840, 'genesis': 1088, 'canon': 381, 'august': 171, 'industrial': 1304, 'output': 1819, 'percent': 1885, 'afp': 35, 'also': 72, 'better': 242, 'head': 1188, 'injury': 1314, 'test': 2667, 'greek': 1133, 'questions': 2069, 'explosives': 899, 'found': 1037, 'plane': 1918, 'wreckage': 2975, 'time': 2701, 'running': 2247, 'quake': 2058, 'government': 1125, 'extend': 903, 'three': 2689, 'year': 2986, 'contract': 562, 'microsoft': 1625, 'hospital': 1243, 'technologies': 2646, 'election': 827, 'threat': 2685, 'howard': 1254, 'qaida': 2054, 'tape': 2636, 'fed': 945, 'hostage': 1245, 'halts': 1170, 'iraq': 1347, 'dolphins': 753, 'trade': 2734, 'kidnappers': 1419, 'say': 2277, 'italian': 1360, 'putin': 2050, 'twin': 2783, 'air': 53, 'crashes': 594, 'battle': 215, 'music': 1698, 'california': 364, 'boom': 294, 'hbos': 1186, 'weighs': 2924, 'abbey': 0, 'bid': 246, 'kabul': 1405, 'bombing': 287, 'security': 2317, 'firm': 984, 'williams': 2936, 'happy': 1179, 'silver': 2411, 'soldiers': 2457, 'charged': 438, 'killings': 1425, 'brain': 310, 'may': 1591, 'slow': 2437, 'around': 133, 'nation': 1712, 'find': 970, 'gop': 1123, 'primary': 1997, 'broken': 330, 'capsule': 388, 'holds': 1226, 'good': 1120, 'hp': 1256, 'smart': 2443, 'winning': 2943, 'touch': 2720, 'soft': 2451, 'cut': 630, 'profit': 2021, 'briefly': 321, 'hires': 1215, 'ad': 20, 'exec': 880, 'powell': 1977, 'misses': 1646, 'medal': 1596, 'lebanese': 1482, 'votes': 2875, 'term': 2661, 'office': 1780, 'silicon': 2409, 'help': 1200, 'explain': 895, 'personal': 1889, 'verizon': 2843, 'key': 1415, 'notre': 1761, 'dame': 640, 'yahoo': 2983, 'patches': 1861, 'hole': 1227, 'control': 564, 'school': 2286, 'siege': 2402, 'wal': 2884, 'mart': 1582, 'slump': 2441, 'keeps': 1411, 'appeals': 109, 'korea': 1434, 'nuke': 1766, 'burundi': 348, 'threaten': 2686, 'congo': 549, 'least': 1479, 'light': 1500, 'cyber': 633, 'award': 182, 'think': 2681, 'space': 2477, 'uk': 2791, 'creates': 597, 'numbers': 1768, 'phone': 1898, 'users': 2829, 'hundreds': 1263, 'fleet': 1002, 'layoffs': 1471, 'expected': 891, 'greece': 1132, 'second': 2312, 'judo': 1398, 'haas': 1161, 'fine': 973, 'form': 1030, 'sharon': 2374, 'accuses': 12, 'far': 929, 'right': 2203, 'civil': 475, 'si': 2399, 'com': 517, 'reporters': 2164, 'past': 1859, 'rugby': 2241, 'calls': 369, 'international': 1329, 'career': 398, 'nortel': 1753, 'losing': 1534, 'pace': 1829, 'moves': 1684, 'deficit': 674, 'australian': 175, 'father': 936, 'action': 18, 'foreign': 1028, 'banks': 203, 'arms': 131, 'hunt': 1267, 'sudanese': 2572, 'fish': 989, 'beach': 221, 'ukraine': 2792, 'lawmakers': 1465, 'agree': 43, 'lost': 1537, 'dreams': 775, 'show': 2391, 'made': 1551, 'pope': 1961, 'returns': 2189, 'quot': 2074, 'rare': 2100, 'orthodox': 1810, 'church': 465, 'soccer': 2450, 'veterans': 2846, 'finale': 965, 'pays': 1871, 'windows': 2939, 'xp': 2982, 'sp': 2475, 'bryant': 339, 'prosecutors': 2033, 'plans': 1924, 'cash': 405, 'athletics': 159, 'teams': 2643, 'hand': 1174, 'foes': 1015, 'open': 1793, 'source': 2469, 'washingtonpost': 2902, 'taps': 2637, 'sprint': 2497, 'provide': 2040, 'voip': 2868, 'indonesia': 1302, 'meeting': 1601, 'urges': 2822, 'broadband': 329, 'growth': 1147, 'slows': 2439, 'analyst': 84, 'heart': 1194, 'future': 1067, 'athlete': 157, 'dies': 717, 'jumps': 1401, 'debut': 661, 'oracle': 1805, 'aims': 52, 'grid': 1139, 'freshman': 1051, 'surgery': 2592, 'uranium': 2819, 'times': 2702, 'former': 1032, 'systems': 2618, 'dead': 652, 'missing': 1649, 'maoist': 1570, 'attack': 163, 'gain': 1069, 'tumble': 2771, 'executive': 882, 'editor': 813, 'gm': 1110, 'online': 1791, 'swiss': 2610, 'host': 1244, 'finishes': 978, 'diving': 743, 'tigers': 2699, 'edge': 810, 'mariners': 1573, 'wild': 2935, 'medical': 1599, 'experts': 894, 'fear': 941, 'charley': 441, 'looking': 1528, 'strong': 2559, 'current': 627, 'account': 10, 'gap': 1074, 'dollar': 751, 'intel': 1323, 'pledges': 1938, 'bring': 323, 'price': 1993, 'point': 1944, 'expos': 901, 'keep': 1409, 'dodgers': 748, 'bay': 217, 'sells': 2331, 'dvd': 792, 'troops': 2760, 'response': 2175, 'spam': 2479, 'lawsuit': 1466, 'federer': 947, 'rolls': 2226, 'fourth': 1039, 'round': 2231, 'hamm': 1172, 'hold': 1224, 'men': 1607, 'triathlon': 2751, 'mobile': 1656, 'makers': 1558, 'message': 1613, 'date': 646, 'set': 2355, 'nhl': 1742, 'german': 1092, 'infineon': 1306, 'million': 1635, 'antitrust': 103, 'working': 2961, 'stop': 2539, 'blame': 264, 'game': 1071, 'baghdad': 192, 'blast': 266, 'planned': 1922, 'target': 2638, 'tv': 2781, 'switch': 2611, 'united': 2802, 'likely': 1502, 'pension': 1879, 'fight': 957, 'kerry': 1414, 'sudan': 2571, 'ill': 1282, 'giant': 1100, 'ipo': 1343, 'speech': 2486, 'become': 226, 'singapore': 2413, 'sets': 2357, 'bln': 269, 'order': 1807, 'days': 650, 'tell': 2655, 'deal': 655, 'brings': 324, 'closer': 496, 'vision': 2862, 'world': 2963, 'henin': 1204, 'hardenne': 1181, 'approach': 117, 'traffic': 2736, 'management': 1564, 'yankees': 2984, 'strike': 2555, 'back': 188, 'leads': 1477, 'orioles': 1809, 'twins': 2784, 'brunei': 338, 'wedding': 2918, 'role': 2224, 'asia': 144, 'seen': 2323, 'wall': 2887, 'street': 2553, 'satellite': 2271, 'holdout': 1225, 'offensive': 1775, 'tackle': 2620, 'signs': 2407, 'rams': 2094, 'hewitt': 1206, 'cubs': 620, 'alert': 63, 'floods': 1008, 'kill': 1421, 'serious': 2349, 'away': 184, 'years': 2987, 'alitalia': 64, 'tells': 2656, 'unions': 2800, 'plan': 1917, 'car': 393, 'bomb': 284, 'police': 1949, 'nokia': 1752, 'handset': 1177, 'doping': 759, 'cost': 578, 'eyes': 908, 'wimax': 2937, 'video': 2851, 'options': 1803, 'britain': 325, 'lewis': 1493, 'french': 1049, 'visit': 2863, 'seek': 2320, 'release': 2150, 'journalists': 1392, 'based': 211, 'company': 529, 'system': 2617, 'server': 2351, 'continue': 560, 'soar': 2448, 'ziff': 2997, 'davis': 648, 'tech': 2645, 'means': 1595, 'next': 1740, 'big': 248, 'thing': 2680, 'vikings': 2854, 'tune': 2773, 'aim': 50, 'party': 1856, 'mergers': 1612, 'problems': 2013, 'recalls': 2126, 'powerbook': 1979, 'batteries': 214, 'maccentral': 1546, 'indian': 1300, 'sent': 2342, 'prison': 2001, 'court': 588, 'sends': 2340, 'minister': 1640, 'middle': 1628, 'east': 803, 'hostages': 1246, 'sox': 2474, 'angels': 89, 'chinese': 461, 'thailand': 2675, 'grey': 1138, 'advertising': 30, 'opens': 1796, 'design': 697, 'blade': 262, 'servers': 2352, 'marlins': 1580, 'miss': 1644, 'reduces': 2135, 'radcliffe': 2080, 'tears': 2644, 'bronze': 334, 'delivers': 680, 'cluster': 502, 'turkey': 2775, 'eu': 867, 'moment': 1660, 'chief': 455, 'worm': 2965, 'turn': 2778, 'parts': 1855, 'women': 2954, 'trail': 2737, 'sadr': 2258, 'najaf': 1705, 'mosque': 1674, 'official': 1781, 'amp': 82, 'vodafone': 2866, 'java': 1373, 'great': 1131, 'escape': 861, 'runs': 2248, 'australia': 174, 'range': 2095, 'missiles': 1648, 'force': 1023, 'toll': 2711, 'reaches': 2113, 'milestone': 1630, 'results': 2179, 'estimates': 865, 'later': 1458, 'place': 1916, 'top': 2715, 'retailer': 2183, 'woodgate': 2955, 'well': 2928, 'sears': 2307, 'board': 279, 'fires': 983, 'green': 1135, 'slam': 2428, 'lifts': 1499, 'teenager': 2651, 'sasser': 2270, 'rooney': 2229, 'hit': 1219, 'hurricane': 1269, 'size': 2423, 'song': 2461, 'bears': 222, 'ford': 1025, 'face': 909, 'class': 480, 'suit': 2580, 'violence': 2856, 'building': 346, 'silent': 2408, 'money': 1662, 'moscow': 1673, 'poverty': 1976, 'fcc': 939, 'adds': 23, 'months': 1664, 'local': 1520, 'rules': 2243, 'prince': 1999, 'decision': 664, 'quarter': 2061, 'earnings': 797, 'expectations': 890, 'india': 1299, 'steps': 2533, 'old': 1787, 'near': 1719, 'dropped': 781, 'tour': 2723, 'invesco': 1334, 'mln': 1655, 'settlement': 2359, 'finish': 977, 'marathon': 1571, 'awaited': 180, 'doom': 757, 'samsung': 2265, 'notebook': 1758, 'browns': 336, 'reach': 2111, 'ravens': 2106, 'billion': 251, 'send': 2337, 'delegation': 678, 'confirms': 546, 'cheers': 449, 'surge': 2591, 'asian': 145, 'prepares': 1987, 'pm': 1943, 'violent': 2857, 'inquiry': 1316, 'watchdog': 2905, 'attacks': 164, 'id': 1277, 'card': 394, 'inflation': 1307, 'way': 2909, 'hong': 1239, 'kong': 1433, 'economy': 809, 'probe': 2009, 'launched': 1462, 'parliament': 1848, 'admits': 24, 'spot': 2494, 'winner': 2941, 'lose': 1532, 'yukos': 2995, 'heat': 1195, 'want': 2888, 'power': 1978, 'go': 1111, 'thatcher': 2677, 'sport': 2492, 'solid': 2458, 'ratings': 2104, 'iran': 1345, 'halt': 1169, 'updates': 2810, 'software': 2453, 'ivan': 1364, 'toward': 2725, 'gulf': 1155, 'coast': 506, 'army': 132, 'destroys': 700, 'homes': 1237, 'bus': 349, 'bombings': 288, 'led': 1484, 'forces': 1024, 'take': 2624, 'health': 1191, 'policy': 1951, 'plays': 1934, 'golden': 1117, 'joy': 1393, 'wrong': 2977, 'largest': 1452, 'computing': 538, 'jobs': 1383, 'slams': 2429, 'north': 1754, 'japan': 1371, 'starts': 2520, 'solution': 2459, 'looks': 1529, 'begins': 230, 'clinches': 492, 'senior': 2341, 'major': 1555, 'job': 1381, 'report': 2160, 'quest': 2066, 'holy': 1233, 'phillies': 1896, 'season': 2308, 'kreme': 1436, 'opener': 1794, 'raise': 2089, 'concerns': 541, 'lion': 1512, 'awaits': 181, 'yen': 2989, 'peak': 1877, 'durable': 789, 'goods': 1121, 'orders': 1808, 'rose': 2230, 'survey': 2595, 'know': 1431, 'economic': 808, 'boosts': 296, 'funds': 1064, 'champion': 429, 'operations': 1798, 'amazon': 74, 'production': 2018, 'miami': 1620, 'beats': 224, 'florida': 1009, 'ot': 1813, 'champions': 430, 'trophy': 2761, 'island': 1353, 'henman': 1205, 'spotlight': 2495, 'advance': 27, 'toyota': 2729, 'pro': 2008, 'union': 2799, 'vows': 2877, 'shut': 2396, 'companies': 528, 'nepal': 1726, 'europe': 869, 'told': 2710, 'stem': 2530, 'cell': 415, 'research': 2170, 'genocide': 1089, 'finding': 971, 'nba': 1716, 'star': 2514, 'cleared': 484, 'minutes': 1643, 'fame': 924, 'winners': 2942, 'bill': 250, 'clinton': 493, 'semifinals': 2334, 'injured': 1312, 'devers': 710, 'today': 2708, 'schedule': 2283, 'itunes': 1363, 'advanced': 28, 'micro': 1624, 'chip': 462, 'appeal': 108, 'tries': 2754, 'acclaim': 8, 'falls': 920, 'settles': 2363, 'overtime': 1823, 'claim': 476, 'joint': 1388, 'venture': 2839, 'pipeline': 1911, 'cricket': 601, 'pressure': 1991, 'young': 2994, 'sharing': 2373, 'kremlin': 1437, 'stage': 2506, 'ny': 1769, 'lukoil': 1544, 'games': 1072, 'rock': 2219, 'thousands': 2684, 'africa': 36, 'madrid': 1552, 'rape': 2099, 'reports': 2165, 'credit': 598, 'news': 1738, 'industry': 1305, 'latest': 1459, 'late': 1457, 'crude': 614, 'slide': 2431, 'jones': 1389, 'fears': 942, 'qwest': 2076, 'settle': 2358, 'cites': 471, 'impact': 1290, 'species': 2485, 'illegal': 1283, 'squad': 2502, 'slovakia': 2436, 'club': 500, 'atlanta': 160, 'vote': 2873, 'democrats': 688, 'jump': 1400, 'summer': 2583, 'like': 1501, 'champ': 428, 'powers': 1981, 'cross': 610, 'mozilla': 1687, 'japanese': 1372, 'push': 2047, 'football': 1021, 'claims': 477, 'lift': 1497, 'hopes': 1242, 'process': 2014, 'make': 1556, 'fuel': 1058, 'fire': 980, 'erupts': 860, 'depot': 693, 'eastern': 804, 'roddick': 2223, 'serena': 2347, 'gdp': 1084, 'revised': 2195, 'pct': 1874, 'market': 1576, 'value': 2834, 'warns': 2899, 'schwab': 2290, 'fined': 974, 'western': 2930, 'cuba': 617, 'sale': 2262, 'rank': 2097, 'slips': 2435, 'woman': 2953, 'remains': 2155, 'healthy': 1192, 'nuclear': 1765, 'capable': 383, 'missile': 1647, 'business': 351, 'ca': 359, 'acquires': 14, 'general': 1086, 'blames': 265, 'abuse': 3, 'contracts': 563, 'treasuries': 2745, 'slip': 2434, 'lower': 1541, 'course': 587, 'bn': 278, 'acquisition': 15, 'moon': 1667, 'landing': 1447, 'draw': 772, 'announces': 97, 'avoid': 179, 'shrine': 2394, 'developers': 706, 'linux': 1511, 'base': 209, 'standard': 2511, 'elections': 828, 'weekend': 2921, 'use': 2827, 'risks': 2211, 'sides': 2401, 'kobe': 1432, 'seeks': 2322, 'truck': 2764, 'payment': 1869, 'realnetworks': 2119, 'slashes': 2430, 'advances': 29, 'run': 2246, 'verisign': 2841, 'icann': 1275, 'state': 2521, 'ii': 1281, 'probes': 2011, 'warner': 2896, 'moving': 1686, 'yanks': 2985, 'remain': 2154, 'jets': 1378, 'spain': 2478, 'summit': 2584, 'ride': 2202, 'wave': 2907, 'ends': 841, 'talk': 2631, 'feds': 949, 'speed': 2487, 'list': 1514, 'said': 2261, 'investigation': 1336, 'match': 1588, 'offer': 1776, 'georgian': 1091, 'center': 419, 'utah': 2832, 'smith': 2444, 'sights': 2405, 'linked': 1509, 'global': 1109, 'warming': 2893, 'labor': 1443, 'weigh': 2923, 'truce': 2763, 'rejected': 2146, 'forbes': 1022, 'nearly': 1720, 'novell': 1762, 'begin': 229, 'public': 2041, 'researchers': 2171, 'cells': 416, 'sex': 2366, 'lines': 1506, 'anti': 102, 'airways': 59, 'delay': 675, 'payments': 1870, 'biggest': 249, 'risk': 2210, 'look': 1527, 'hot': 1247, 'mp': 1688, 'player': 1930, 'airbus': 54, 'planes': 1919, 'audit': 168, 'venezuelan': 2838, 'chavez': 443, 'defeat': 669, 'ers': 859, 'qb': 2056, 'fishing': 990, 'bite': 258, 'return': 2188, 'reality': 2118, 'step': 2532, 'bombers': 286, 'jet': 1377, 'commercial': 525, 'service': 2353, 'caller': 367, 'ipod': 1344, 'media': 1598, 'wto': 2979, 'effort': 818, 'law': 1464, 'posts': 1972, 'another': 99, 'nice': 1743, 'mixed': 1653, 'govt': 1127, 'basketball': 212, 'brazil': 313, 'calling': 368, 'pair': 1836, 'rangers': 2096, 'must': 1701, 'european': 870, 'casts': 407, 'shadow': 2367, 'field': 955, 'influence': 1308, 'platform': 1927, 'baseball': 210, 'outlines': 1817, 'tougher': 2722, 'pakistan': 1838, 'real': 2117, 'blair': 263, 'trying': 2769, 'symbol': 2615, 'relief': 2153, 'tri': 2748, 'nations': 1714, 'complete': 533, 'recovery': 2131, 'unclear': 2795, 'peaceful': 1876, 'imf': 1288, 'kenya': 1413, 'rebels': 2121, 'fury': 1066, 'beware': 243, 'water': 2906, 'rises': 2208, 'low': 1539, 'sweep': 2606, 'straight': 2547, 'day': 649, 'track': 2731, 'fighting': 958, 'rages': 2083, 'ossetia': 1812, 'memos': 1606, 'guard': 1149, 'helped': 1201, 'rate': 2101, 'hikes': 1212, 'view': 2853, 'dream': 774, 'dips': 723, 'steel': 2529, 'braces': 309, 'storm': 2544, 'el': 825, 'guerrouj': 1150, 'holmes': 1232, 'doubles': 762, 'americans': 79, 'yield': 2991, 'services': 2354, 'expansion': 888, 'focus': 1014, 'grows': 1146, 'jamaica': 1369, 'search': 2305, 'vivendi': 2865, 'fun': 1061, 'mean': 1594, 'bhp': 245, 'ball': 195, 'collapse': 512, 'fast': 931, 'rival': 2212, 'road': 2216, 'analysts': 85, 'republican': 2166, 'shuttle': 2398, 'damage': 638, 'manning': 1567, 'carolina': 400, 'lebanon': 1483, 'urged': 2821, 'falling': 919, 'tool': 2713, 'hurricanes': 1270, 'terrorist': 2665, 'competition': 531, 'potential': 1973, 'frances': 1041, 'damages': 639, 'palestinians': 1842, 'west': 2929, 'break': 314, 'country': 584, 'caribbean': 399, 'towards': 2726, 'terrorism': 2664, 'downed': 765, 'offers': 1779, 'rebel': 2120, 'image': 1286, 'fix': 993, 'refugees': 2140, 'italy': 1362, 'morgan': 1670, 'cancels': 377, 'pact': 1832, 'tumbles': 2772, 'final': 964, 'tax': 2640, 'atlantic': 161, 'league': 1478, 'extends': 904, 'blocking': 272, 'month': 1663, 'weather': 2915, 'targets': 2639, 'exercise': 884, 'cancer': 378, 'arrests': 136, 'weapons': 2914, 'needed': 1724, 'climbs': 491, 'vietnam': 2852, 'flat': 998, 'gains': 1070, 'waves': 2908, 'mid': 1626, 'cap': 382, 'choice': 464, 'preview': 1992, 'mortar': 1671, 'radical': 2081, 'cleric': 487, 'france': 1040, 'kidnapped': 1418, 'suspected': 2598, 'file': 960, 'count': 582, 'programs': 2024, 'cent': 418, 'downloads': 768, 'points': 1945, 'owen': 1824, 'mars': 1581, 'scientist': 2293, 'jakarta': 1368, 'mylan': 1703, 'trading': 2735, 'pcs': 1873, 'loss': 1535, 'royals': 2240, 'rout': 2234, 'rebound': 2122, 'compensation': 530, 'leaders': 1475, 'prepare': 1986, 'october': 1773, 'poll': 1955, 'crash': 593, 'gas': 1076, 'hike': 1211, 'roll': 2225, 'cause': 411, 'flight': 1005, 'product': 2017, 'roundup': 2232, 'part': 1850, 'newsfactor': 1739, 'third': 2682, 'raids': 2086, 'stores': 2543, 'rejects': 2147, 'resolution': 2174, 'drought': 783, 'doj': 750, 'fraud': 1043, 'sender': 2338, 'drop': 780, 'democracy': 687, 'philippine': 1894, 'sept': 2345, 'quick': 2070, 'week': 2920, 'pleads': 1936, 'guilty': 1153, 'gazprom': 1082, 'truckers': 2765, 'ual': 2788, 'replace': 2159, 'powerful': 1980, 'strength': 2554, 'cingular': 466, 'program': 2023, 'victim': 2848, 'success': 2570, 'wait': 2881, 'suspects': 2599, 'planning': 1923, 'aug': 170, 'accused': 11, 'side': 2400, 'marketing': 1577, 'african': 37, 'plant': 1925, 'tokyo': 2709, 'cable': 361, 'access': 7, 'rule': 2242, 'wrap': 2974, 'teen': 2650, 'evidence': 877, 'exports': 900, 'beckham': 225, 'images': 1287, 'interim': 1328, 'dividend': 742, 'half': 1165, 'wariner': 2892, 'polish': 1952, 'wants': 2890, 'quiet': 2071, 'aziz': 185, 'elected': 826, 'pak': 1837, 'amid': 80, 'boycott': 307, 'rest': 2176, 'rights': 2204, 'appears': 111, 'tip': 2704, 'reserve': 2172, 'grabs': 1129, 'plot': 1939, 'sunday': 2586, 'mourns': 1681, 'victims': 2849, 'martin': 1584, 'triumph': 2757, 'siemens': 2403, 'flaw': 999, 'york': 2993, 'delivery': 681, 'halliburton': 1168, 'tower': 2727, 'stay': 2526, 'jobless': 1382, 'stalls': 2509, 'ok': 1785, 'mercenary': 1609, 'egypt': 820, 'rally': 2092, 'save': 2276, 'texas': 2671, 'mercenaries': 1608, 'farmers': 930, 'changes': 435, 'deals': 656, 'blow': 275, 'efforts': 819, 'puts': 2051, 'mountain': 1679, 'fischer': 988, 'fails': 915, 'making': 1560, 'love': 1538, 'sign': 2406, 'sharply': 2375, 'hockey': 1223, 'kashmir': 1407, 'abuses': 4, 'released': 2151, 'animals': 93, 'danger': 641, 'astros': 155, 'playoff': 1933, 'race': 2077, 'pushes': 2048, 'pa': 1828, 'shell': 2376, 'nigeria': 1744, 'ireland': 1350, 'peace': 1875, 'products': 2019, 'hackers': 1162, 'victory': 2850, 'ba': 186, 'debt': 660, 'qantas': 2055, 'nl': 1750, 'notables': 1757, 'hopeful': 1241, 'astronomers': 154, 'planets': 1921, 'yet': 2990, 'malaysia': 1561, 'anwar': 104, 'freed': 1046, 'firefox': 982, 'packers': 1831, 'panthers': 1844, 'delta': 683, 'embrace': 836, 'military': 1633, 'details': 701, 'dual': 786, 'core': 574, 'consumers': 556, 'tvs': 2782, 'usatoday': 2825, 'walk': 2885, 'euro': 868, 'ever': 874, 'bond': 290, 'clears': 485, 'safety': 2260, 'panel': 1843, 'explosion': 897, 'guide': 1152, 'catch': 408, 'sun': 2585, 'fresh': 1050, 'despite': 699, 'homer': 1235, 'seat': 2309, 'usa': 2824, 'investor': 1338, 'daily': 637, 'error': 858, 'fly': 1011, 'bounty': 302, 'conviction': 569, 'kids': 1420, 'wpp': 2973, 'routers': 2236, 'effect': 816, 'history': 1218, 'distance': 741, 'finals': 967, 'bodies': 281, 'turkish': 2776, 'display': 738, 'putting': 2052, 'peril': 1888, 'seven': 2364, 'teens': 2652, 'abu': 2, 'ghraib': 1098, 'james': 1370, 'england': 844, 'tests': 2670, 'positive': 1966, 'drugs': 785, 'best': 240, 'proposal': 2031, 'black': 259, 'envoy': 853, 'stock': 2536, 'pitcher': 1915, 'pop': 1960, 'fired': 981, 'denies': 690, 'info': 1309, 'upsets': 2818, 'mom': 1659, 'ease': 801, 'sco': 2295, 'needs': 1725, 'syria': 2616, 'finland': 979, 'cup': 622, 'boxing': 305, 'khan': 1416, 'haiti': 1164, 'mice': 1621, 'flex': 1003, 'builds': 347, 'robot': 2217, 'walks': 2886, 'shares': 2372, 'without': 2949, 'asean': 143, 'ministers': 1641, 'spy': 2500, 'need': 1723, 'merger': 1611, 'sprinters': 2499, 'fujitsu': 1059, 'ally': 69, 'opposition': 1800, 'surprise': 2593, 'mlb': 1654, 'split': 2491, 'double': 760, 'cameras': 372, 'afghanistan': 33, 'dismissed': 735, 'refuses': 2141, 'kmart': 1429, 'hard': 1180, 'defends': 672, 'milosevic': 1637, 'federal': 946, 'judge': 1395, 'rain': 2088, 'sparks': 2483, 'emergency': 838, 'virginia': 2859, 'grenada': 1137, 'bird': 254, 'flu': 1010, 'outside': 1820, 'zone': 2999, 'travel': 2744, 'child': 457, 'change': 433, 'revises': 2196, 'annual': 98, 'nestle': 1728, 'deadline': 653, 'brown': 335, 'family': 926, 'volume': 2871, 'threatens': 2687, 'macromedia': 1548, 'builder': 345, 'tough': 2721, 'enough': 845, 'notes': 1759, 'safer': 2259, 'nightmare': 1747, 'captain': 390, 'airlines': 57, 'holiday': 1229, 'gateway': 1078, 'cutting': 632, 'five': 992, 'delays': 677, 'trip': 2756, 'put': 2049, 'discuss': 732, 'ads': 25, 'groups': 1143, 'buckingham': 340, 'palace': 1840, 'batman': 213, 'prompts': 2030, 'full': 1060, 'white': 2931, 'longhorn': 1526, 'launch': 1461, 'bad': 190, 'blasts': 267, 'scandal': 2281, 'performance': 1887, 'earns': 798, 'baby': 187, 'mother': 1675, 'clear': 483, 'name': 1706, 'ban': 196, 'guantanamo': 1148, 'sea': 2302, 'netflix': 1730, 'laser': 1454, 'environment': 852, 'outlook': 1818, 'answers': 101, 'early': 796, 'recalled': 2125, 'harrington': 1183, 'spyware': 2501, 'solar': 2454, 'xm': 2981, 'short': 2388, 'chain': 424, 'store': 2542, 'slightly': 2433, 'zealand': 2996, 'bonuses': 292, 'thin': 2679, 'orange': 1806, 'fixing': 995, 'businesses': 352, 'berlusconi': 238, 'condemns': 542, 'reported': 2161, 'engine': 843, 'santander': 2268, 'blackberry': 260, 'russians': 2252, 'eight': 822, 'appear': 110, 'golf': 1119, 'lashes': 1455, 'gartner': 1075, 'share': 2370, 'resigns': 2173, 'coke': 509, 'lowers': 1542, 'shifts': 2378, 'result': 2178, 'friends': 1054, 'proves': 2039, 'ships': 2383, 'works': 2962, 'blind': 268, 'bea': 220, 'hat': 1184, 'appoints': 116, 'cfo': 423, 'souness': 2468, 'newcastle': 1737, 'boss': 299, 'broncos': 333, 'bids': 247, 'wsj': 2978, 'lineup': 1507, 'draft': 770, 'sanctions': 2267, 'deserter': 696, 'jenkins': 1376, 'warning': 2897, 'devil': 713, 'rays': 2108, 'hours': 1250, 'interbrew': 1326, 'ambev': 75, 'create': 596, 'ground': 1141, 'fights': 959, 'chicago': 454, 'toronto': 2717, 'ministry': 1642, 'disrupt': 740, 'facing': 911, 'behind': 231, 'bars': 208, 'delayed': 676, 'threats': 2688, 'within': 2948, 'pack': 1830, 'markets': 1578, 'september': 2346, 'peoplesoft': 1883, 'dozens': 769, 'slain': 2427, 'judges': 1396, 'legal': 1487, 'clean': 482, 'act': 17, 'pain': 1835, 'warn': 2894, 'flaws': 1000, 'loses': 1533, 'pilot': 1906, 'factory': 913, 'forecasts': 1027, 'files': 961, 'memory': 1605, 'technology': 2647, 'chess': 453, 'supply': 2588, 'paper': 1845, 'causes': 412, 'suicide': 2578, 'sources': 2470, 'arm': 130, 'michael': 1622, 'boost': 295, 'ryder': 2253, 'goal': 1112, 'agency': 41, 'intensifies': 1325, 'auto': 176, 'capture': 391, 'medals': 1597, 'rallies': 2091, 'volleyball': 2870, 'washington': 2901, 'hungarian': 1264, 'punch': 2046, 'michigan': 1623, 'capriati': 386, 'interoperability': 1331, 'upset': 2817, 'expands': 887, 'mexico': 1618, 'growing': 1145, 'partnership': 1854, 'veritas': 2842, 'named': 1707, 'partners': 1853, 'davenport': 647, 'handed': 1175, 'beijing': 232, 'journalist': 1391, 'quarterly': 2063, 'rising': 2209, 'lenovo': 1488, 'soon': 2464, 'reveal': 2190, 'unit': 2801, 'stripped': 2557, 'fund': 1062, 'capital': 385, 'wi': 2932, 'fi': 954, 'dementieva': 686, 'southern': 2472, 'movie': 1685, 'box': 304, 'enterprise': 848, 'jays': 1374, 'curbs': 624, 'computer': 536, 'projects': 2027, 'bin': 253, 'laden': 1445, 'slides': 2432, 'river': 2214, 'climb': 490, 'nets': 1731, 'score': 2296, 'difficult': 718, 'predict': 1985, 'bankruptcy': 202, 'protection': 2035, 'embassy': 835, 'mets': 1616, 'iaea': 1273, 'poland': 1947, 'row': 2238, 'die': 715, 'bobby': 280, 'usc': 2826, 'almost': 70, 'every': 876, 'area': 127, 'raiders': 2085, 'added': 22, 'criticism': 607, 'grand': 1130, 'helps': 1203, 'lawyers': 1469, 'anglers': 91, 'overcomes': 1822, 'belgian': 234, 'prix': 2006, 'friday': 1052, 'expects': 892, 'possible': 1967, 'telecom': 2653, 'feature': 943, 'forward': 1035, 'fat': 934, 'scare': 2282, 'muslim': 1700, 'monty': 1665, 'hk': 1222, 'clash': 478, 'northern': 1755, 'royal': 2239, 'sought': 2466, 'increases': 1297, 'spending': 2488, 'militant': 1631, 'ohio': 1783, 'dna': 745, 'fingerprint': 976, 'homers': 1236, 'fit': 991, 'ietf': 1280, 'amd': 76, 'inside': 1317, 'musharraf': 1697, 'islamic': 1352, 'athletes': 158, 'helping': 1202, 'debate': 659, 'gates': 1077, 'mail': 1554, 'chairman': 425, 'caps': 387, 'losses': 1536, 'mount': 1678, 'mini': 1639, 'drives': 779, 'calif': 363, 'schools': 2287, 'warned': 2895, 'identity': 1278, 'theft': 2678, 'route': 2235, 'clemens': 486, 'nine': 1749, 'streak': 2552, 'bonds': 291, 'brokers': 332, 'estate': 864, 'consider': 552, 'plea': 1935, 'picks': 1902, 'karzai': 1406, 'curfew': 625, 'rd': 2110, 'driver': 777, 'retire': 2185, 'pitch': 1914, 'arrested': 135, 'drama': 771, 'secure': 2316, 'swimming': 2608, 'records': 2130, 'peirsol': 1878, 'flights': 1006, 'worth': 2969, 'mulls': 1693, 'sports': 2493, 'de': 651, 'la': 1441, 'expert': 893, 'deaths': 658, 'hollywood': 1231, 'fail': 914, 'sell': 2329, 'tickets': 2694, 'transactions': 2741, 'hotel': 1248, 'bombs': 289, 'barrier': 207, 'eriksson': 857, 'situation': 2420, 'following': 1017, 'massacre': 1586, 'hints': 1214, 'houston': 1253, 'rating': 2103, 'reform': 2137, 'tops': 2716, 'concern': 539, 'phishing': 1897, 'freddie': 1044, 'poor': 1959, 'shape': 2368, 'spammers': 2480, 'venezuela': 2837, 'vendor': 2836, 'support': 2589, 'number': 1767, 'snaps': 2447, 'europeans': 871, 'night': 1746, 'seattle': 2310, 'suffers': 2576, 'per': 1884, 'nigerian': 1745, 'senate': 2336, 'starting': 2519, 'zimbabwe': 2998, 'refugee': 2139, 'aid': 47, 'espn': 863, 'regulator': 2143, 'room': 2228, 'modest': 1658, 'investment': 1337, 'ulmer': 2793, 'carter': 402, 'suisse': 2579, 'ask': 146, 'block': 270, 'status': 2525, 'blockade': 271, 'giambi': 1099, 'mcafee': 1592, 'motley': 1676, 'fool': 1020, 'jackson': 1365, 'buzz': 358, 'earth': 799, 'larsson': 1453, 'celtic': 417, 'fan': 927, 'insurers': 1320, 'aiming': 51, 'analysis': 83, 'deliver': 679, 'stays': 2527, 'titans': 2705, 'hidden': 1207, 'crm': 609, 'supreme': 2590, 'crimes': 603, 'dept': 694, 'donald': 755, 'masters': 1587, 'information': 1311, 'probed': 2010, 'wine': 2940, 'raises': 2090, 'reached': 2112, 'cal': 362, 'readies': 2114, 'app': 107, 'upgrade': 2811, 'conflict': 547, 'link': 1508, 'disease': 733, 'witness': 2950, 'immunity': 1289, 'flash': 997, 'missed': 1645, 'chance': 432, 'adultery': 26, 'project': 2026, 'browser': 337, 'struggles': 2561, 'recent': 2127, 'lows': 1543, 'cool': 570, 'weak': 2911, 'suits': 2581, 'presidential': 1989, 'cloud': 499, 'income': 1295, 'defense': 673, 'kathmandu': 1408, 'hdtv': 1187, 'links': 1510, 'assault': 149, 'strategy': 2550, 'critics': 608, 'flee': 1001, 'arrest': 134, 'iranian': 1346, 'rookie': 2227, 'stops': 2540, 'let': 1490, 'sued': 2574, 'spanish': 2481, 'eds': 814, 'sap': 2269, 'applications': 114, 'privacy': 2004, 'cardinals': 395, 'coral': 573, 'private': 2005, 'rocket': 2220, 'explodes': 896, 'reopen': 2157, 'honda': 1238, 'annan': 94, 'tie': 2695, 'aussies': 173, 'king': 1428, 'bills': 252, 'woes': 2952, 'voters': 2874, 'aide': 48, 'surrender': 2594, 'assets': 152, 'moore': 1669, 'called': 366, 'criminal': 604, 'fewer': 953, 'students': 2562, 'defence': 671, 'lawyer': 1468, 'dent': 691, 'upgrades': 2812, 'gunmen': 1157, 'briton': 327, 'corporate': 576, 'dip': 721, 'computers': 537, 'convention': 567, 'imports': 1292, 'stall': 2508, 'many': 1569, 'extension': 905, 'mortgage': 1672, 'electronics': 831, 'available': 177, 'mauresmo': 1590, 'virtual': 2860, 'highlights': 1210, 'brand': 311, 'sprinter': 2498, 'suspension': 2602, 'rouse': 2233, 'since': 2412, 'virgin': 2858, 'soars': 2449, 'greenspan': 1136, 'benefit': 236, 'postponed': 1970, 'related': 2148, 'players': 1931, 'rush': 2249, 'consumer': 555, 'tonight': 2712, 'funk': 1065, 'pound': 1974, 'clashes': 479, 'robson': 2218, 'beslan': 239, 'cowboys': 590, 'seahawks': 2303, 'failure': 916, 'fault': 937, 'pulls': 2045, 'shopping': 2387, 'demands': 685, 'bans': 204, 'energy': 842, 'mac': 1545, 'os': 1811, 'vw': 2879, 'national': 1713, 'munch': 1694, 'scream': 2299, 'stolen': 2538, 'connect': 551, 'alliance': 67, 'announce': 96, 'bangladesh': 198, 'climate': 489, 'tribunal': 2752, 'ufj': 2790, 'division': 744, 'softball': 2452, 'storage': 2541, 'dismisses': 736, 'mystery': 1704, 'kroger': 1439, 'islands': 1354, 'renault': 2156, 'bali': 194, 'going': 1115, 'rivals': 2213, 'lands': 1448, 'girl': 1103, 'pinsent': 1909, 'anniversary': 95, 'hope': 1240, 'unemployment': 2796, 'steady': 2528, 'declines': 667, 'fifth': 956, 'problem': 2012, 'uses': 2830, 'paid': 1834, 'barrichello': 206, 'plants': 1926, 'shiite': 2379, 'arrives': 138, 'watch': 2904, 'tunes': 2774, 'drive': 776, 'employees': 839, 'sentenced': 2344, 'training': 2740, 'getting': 1097, 'arrive': 137, 'small': 2442, 'telescope': 2654, 'captures': 392, 'draws': 773, 'suspended': 2600, 'manufacturing': 1568, 'confidence': 544, 'goals': 1113, 'awards': 183, 'pentagon': 1881, 'deng': 689, 'crackdown': 591, 'worries': 2966, 'bae': 191, 'saddam': 2257, 'reportedly': 2162, 'schering': 2284, 'plough': 1940, 'bayer': 218, 'indonesian': 1303, 'tackles': 2621, 'budget': 341, 'level': 1492, 'ousted': 1815, 'ms': 1690, 'releases': 2152, 'testing': 2669, 'culture': 621, 'flies': 1004, 'downer': 766, 'sybase': 2613, 'express': 902, 'database': 645, 'copyright': 572, 'revenge': 2192, 'confusion': 548, 'fate': 935, 'discounts': 729, 'sues': 2575, 'barrel': 205, 'jpeg': 1394, 'parties': 1851, 'import': 1291, 'gymnastics': 1160, 'scoring': 2298, 'close': 495, 'stars': 2516, 'indians': 1301, 'rb': 2109, 'weeks': 2922, 'perfect': 1886, 'saudi': 2274, 'confident': 545, 'pole': 1948, 'debuts': 662, 'diebold': 716, 'libya': 1495, 'nears': 1721, 'ranking': 2098, 'dig': 719, 'machine': 1547, 'ice': 1276, 'expect': 889, 'cube': 619, 'hall': 1167, 'joins': 1387, 'arabia': 124, 'smithfield': 2445, 'buying': 355, 'foods': 1019, 'table': 2619, 'directors': 725, 'train': 2739, 'rockies': 2221, 'gibbs': 1102, 'redskins': 2134, 'militia': 1634, 'colorado': 514, 'taking': 2629, 'epson': 854, 'develops': 709, 'flying': 1012, 'battles': 216, 'transmeta': 2743, 'questioned': 2068, 'body': 282, 'egyptian': 821, 'playing': 1932, 'friendly': 1053, 'deutsche': 703, 'boston': 300, 'scientific': 2292, 'stent': 2531, 'tied': 2696, 'assembly': 150, 'futures': 1068, 'sold': 2455, 'northwest': 1756, 'clients': 488, 'approve': 120, 'upon': 2814, 'conference': 543, 'chechnya': 447, 'wage': 2880, 'fees': 951, 'aids': 49, 'event': 873, 'quits': 2073, 'sluggish': 2440, 'motorola': 1677, 'bell': 235, 'selling': 2330, 'little': 1516, 'pull': 2043, 'producer': 2016, 'nowhere': 1763, 'london': 1523, 'promises': 2029, 'care': 397, 'heinz': 1197, 'gov': 1124, 'arab': 123, 'shuts': 2397, 'boy': 306, 'currency': 626, 'visits': 2864, 'upbeat': 2808, 'reject': 2145, 'owners': 1826, 'lock': 1521, 'dispute': 739, 'fiscal': 987, 'hill': 1213, 'ancient': 86, 'left': 1486, 'airport': 58, 'hamas': 1171, 'ring': 2205, 'opening': 1795, 'polls': 1956, 'phones': 1899, 'tiny': 2703, 'nfl': 1741, 'summary': 2582, 'im': 1284, 'dangerous': 642, 'gymnast': 1159, 'saudis': 2275, 'traction': 2733, 'tivo': 2707, 'widens': 2934, 'grow': 1144, 'desktop': 698, 'knee': 1430, 'johnson': 1385, 'demand': 684, 'saboteurs': 2256, 'email': 834, 'invest': 1335, 'takeover': 2626, 'becomes': 227, 'hub': 1258, 'ramirez': 2093, 'using': 2831, 'strained': 2549, 'nanometer': 1709, 'cheney': 452, 'comments': 523, 'freeze': 1048, 'lets': 1491, 'agencies': 40, 'krispy': 1438, 'scales': 2280, 'weaker': 2912, 'bounce': 301, 'ruling': 2244, 'commerce': 524, 'decide': 663, 'crew': 600, 'strain': 2548, 'circulation': 469, 'referendum': 2136, 'unfazed': 2798, 'settlements': 2360, 'bbc': 219, 'cycling': 635, 'san': 2266, 'francisco': 1042, 'saturday': 2272, 'qtr': 2057, 'revenue': 2193, 'controversy': 566, 'revolt': 2197, 'border': 297, 'political': 1953, 'sinks': 2416, 'cases': 404, 'sistani': 2417, 'howe': 1255, 'langer': 1449, 'states': 2523, 'quarters': 2064, 'tactics': 2622, 'unlikely': 2805, 'photo': 1900, 'eclipse': 807, 'among': 81, 'storms': 2545, 'cheap': 444, 'fbi': 938, 'semiconductor': 2333, 'southwest': 2473, 'due': 787, 'killer': 1423, 'suggests': 2577, 'sendo': 2339, 'director': 724, 'sue': 2573, 'voting': 2876, 'mr': 1689, 'ntt': 1764, 'docomo': 746, 'irish': 1351, 'prisoner': 2002, 'trim': 2755, 'equipment': 856, 'cities': 472, 'counties': 583, 'racing': 2079, 'survives': 2596, 'recall': 2124, 'funding': 1063, 'hammer': 1173, 'rail': 2087, 'sweet': 2607, 'food': 1018, 'disarm': 726, 'dow': 764, 'jury': 1403, 'forms': 1033, 'path': 1863, 'pga': 1891, 'keeping': 1410, 'chelsea': 450, 'heavy': 1196, 'text': 2672, 'prisoners': 2003, 'hunger': 1266, 'reading': 2115, 'wary': 2900, 'latham': 1460, 'paris': 1846, 'celebrates': 414, 'serve': 2350, 'mine': 1638, 'doubleheader': 761, 'pirates': 1913, 'strikes': 2556, 'cars': 401, 'fee': 950, 'ubs': 2789, 'coverage': 589, 'voice': 2867, 'fans': 928, 'diplomats': 722, 'edges': 811, 'mourinho': 1680, 'hands': 1176, 'sd': 2301, 'protesters': 2037, 'check': 448, 'live': 1517, 'hitachi': 1220, 'ups': 2816, 'plunge': 1942, 'ftc': 1057, 'networks': 1734, 'closing': 498, 'trouble': 2762, 'seize': 2325, 'opportunity': 1799, 'march': 1572, 'jail': 1366, 'detroit': 702, 'wounded': 2971, 'padres': 1833, 'apps': 122, 'gb': 1083, 'duo': 788, 'customer': 628, 'shoots': 2385, 'picture': 1903, 'maker': 1557, 'position': 1965, 'setback': 2356, 'shines': 2380, 'chiefs': 456, 'held': 1198, 'changed': 434, 'passes': 1858, 'chargers': 439, 'hollinger': 1230, 'skills': 2424, 'dollars': 752, 'coca': 507, 'cola': 510, 'jimenez': 1380, 'less': 1489, 'sosa': 2465, 'resumes': 2181, 'los': 1531, 'angeles': 88, 'true': 2766, 'raid': 2084, 'june': 1402, 'ties': 2697, 'sweden': 2605, 'reward': 2199, 'mix': 1652, 'arafat': 125, 'mistakes': 1651, 'stewart': 2534, 'everton': 875, 'across': 16, 'dog': 749, 'journal': 1390, 'ink': 1315, 'add': 21, 'struggle': 2560, 'beer': 228, 'rnc': 2215, 'withdraw': 2946, 'saturn': 2273, 'given': 1105, 'population': 1963, 'policies': 1950, 'starter': 2518, 'children': 458, 'musicmatch': 1699, 'symantec': 2614, 'semi': 2332, 'scores': 2297, 'inc': 1294, 'disk': 734, 'shareholders': 2371, 'cloning': 494, 'question': 2067, 'trojan': 2758, 'complaint': 532, 'salvador': 2264, 'israelis': 1357, 'alleged': 66, 'unfair': 2797, 'practices': 1983, 'transfer': 2742, 'handsets': 1178, 'quarterfinals': 2062, 'pinochet': 1908, 'chile': 459, 'extra': 906, 'series': 2348, 'marines': 1574, 'villeneuve': 2855, 'freestyle': 1047, 'longer': 1525, 'challenge': 426, 'suzuki': 2604, 'corp': 575, 'tools': 2714, 'hubble': 1259, 'allows': 68, 'settler': 2361, 'developer': 705, 'managers': 1566, 'asset': 151, 'manager': 1565, 'candidates': 380, 'retailers': 2184, 'argentina': 128, 'easy': 805, 'golds': 1118, 'college': 513, 'even': 872, 'studios': 2564, 'justice': 1404, 'cracks': 592, 'crime': 602, 'terms': 2662, 'borland': 298, 'studio': 2563, 'colts': 515, 'mass': 1585, 'large': 1451, 'capsules': 389, 'britons': 328, 'download': 767, 'rip': 2206, 'gear': 1085, 'factories': 912, 'benefits': 237, 'chase': 442, 'reporter': 2163, 'secret': 2313, 'sector': 2315, 'counts': 585, 'reveals': 2191, 'deep': 668, 'clues': 501, 'fines': 975, 'breaking': 315, 'ear': 795, 'camera': 371, 'millions': 1636, 'eisner': 824, 'ways': 2910, 'brief': 320, 'follow': 1016, 'standards': 2512, 'malaysian': 1562, 'screen': 2300, 'fla': 996, 'vaccine': 2833, 'circuit': 468, 'optimism': 1802, 'toshiba': 2718, 'nepalese': 1727, 'station': 2524, 'format': 1031, 'jazeera': 1375, 'guidant': 1151, 'council': 581, 'pioneer': 1910, 'film': 963, 'dominates': 754, 'leading': 1476, 'sbc': 2279, 'hails': 1163, 'birth': 255, 'paul': 1866, 'enter': 847, 'politics': 1954, 'bit': 257, 'slower': 2438, 'halfway': 1166, 'introduces': 1333, 'crown': 612, 'testimony': 2668, 'giving': 1107, 'answer': 100, 'nz': 1771, 'coming': 522, 'rescue': 2169, 'region': 2142, 'fm': 1013, 'offerings': 1778, 'idf': 1279, 'operation': 1797, 'camp': 373, 'lives': 1519, 'rocks': 2222, 'mark': 1575, 'buick': 343, 'marks': 1579, 'playboy': 1929, 'wide': 2933, 'foster': 1036, 'cooperation': 571, 'sabotage': 2255, 'iraqis': 1349, 'rebounds': 2123, 'urge': 2820, 'madden': 1550, 'revolution': 2198, 'reforms': 2138, 'belarus': 233, 'arizona': 129, 'mutual': 1702, 'nazi': 1715, 'try': 2768, 'artisan': 142, 'america': 77, 'cruises': 616, 'taliban': 2630, 'ray': 2107, 'parmalat': 1849, 'repair': 2158, 'derail': 695, 'rumsfeld': 2245, 'doubt': 763, 'pollution': 1957, 'developing': 707, 'town': 2728, 'sound': 2467, 'searches': 2306, 'kuznetsova': 1440, 'nyc': 1770, 'snap': 2446, 'sa': 2254, 'georgia': 1090, 'sutton': 2603, 'schilling': 2285, 'pakistani': 1839, 'spa': 2476, 'practice': 1982, 'application': 113, 'patriots': 1864, 'weakness': 2913, 'holes': 1228, 'tribune': 2753, 'columnists': 516, 'recognition': 2128, 'done': 756, 'tiger': 2698, 'creditors': 599, 'centrino': 421, 'cease': 413, 'develop': 704, 'rovers': 2237, 'messaging': 1614, 'anger': 90, 'arroyo': 139, 'aussie': 172, 'qaeda': 2053, 'seeking': 2321, 'shoppers': 2386, 'wanted': 2889, 'seventh': 2365, 'discovered': 730, 'philippines': 1895, 'single': 2415, 'financial': 969, 'combat': 518, 'anxious': 105, 'special': 2484, 'filing': 962, 'banker': 200, 'championship': 431, 'treasury': 2746, 'brewers': 318, 'hiring': 1216, 'mad': 1549, 'hare': 1182, 'au': 166, 'td': 2641, 'banknorth': 201, 'cuban': 618, 'afghans': 34, 'kim': 1427, 'museum': 1696, 'quattrone': 2065, 'jailed': 1367, 'beyond': 244, 'suspect': 2597, 'curb': 623, 'wake': 2883, 'limits': 1504, 'veteran': 2845, 'oxygen': 1827, 'generator': 1087, 'insurance': 1319, 'disc': 728, 'thai': 2674, 'devices': 712, 'guy': 1158, 'blows': 276, 'straw': 2551, 'vonage': 2872, 'oakland': 1772, 'fedex': 948, 'starbucks': 2515, 'pricing': 1995, 'tanks': 2634, 'breakthrough': 317, 'defeats': 670, 'wrestling': 2976, 'expand': 886, 'emc': 837, 'swing': 2609, 'nasdaq': 1711, 'plummets': 1941, 'retreat': 2187, 'trend': 2747, 'families': 925, 'gerrard': 1094, 'gather': 1079, 'witnesses': 2951, 'fallujah': 922, 'stand': 2510, 'continental': 559, 'ft': 1056, 'siliconvalley': 2410, 'schroeder': 2288, 'enters': 850, 'crawford': 595, 'briefs': 322, 'patterson': 1865, 'faster': 932, 'withdrawal': 2947, 'wounds': 2972, 'restructuring': 2177, 'yemeni': 2988, 'stroke': 2558, 'profile': 2020, 'pensions': 1880, 'considers': 553, 'shift': 2377, 'ago': 42, 'braves': 312, 'books': 293, 'explosions': 898, 'hybrid': 1272, 'come': 519, 'self': 2327, 'worldwide': 2964, 'shipments': 2382, 'venus': 2840, 'blood': 273, 'cos': 577, 'via': 2847, 'races': 2078, 'eighth': 823, 'chechens': 446, 'bomber': 285, 'brace': 308, 'opts': 1804, 'welcomes': 2927, 'uprising': 2815, 'spots': 2496, 'classic': 481, 'paying': 1868, 'techweb': 2649, 'talking': 2632, 'float': 1007, 'terrorists': 2666, 'convicted': 568, 'ticket': 2693, 'edition': 812, 'son': 2460, 'processor': 2015, 'selig': 2328, 'completes': 534, 'lockout': 1522, 'pool': 1958, 'interview': 1332, 'intelligence': 1324, 'challenges': 427, 'waiting': 2882, 'congress': 550, 'liverpool': 1518, 'weightlifter': 2925, 'touts': 2724, 'human': 1262, 'grip': 1140, 'throw': 2690, 'land': 1446, 'infocus': 1310, 'improve': 1293, 'mode': 1657, 'showdown': 2392, 'unveil': 2806, 'jewish': 1379, 'rfid': 2200, 'quota': 2075, 'sixth': 2422, 'lithuania': 1515, 'trials': 2750, 'italians': 1361, 'concerned': 540, 'coalition': 505, 'actions': 19, 'lawsuits': 1467, 'aircraft': 55, 'upholds': 2813, 'martha': 1583, 'hearing': 1193, 'nothing': 1760, 'band': 197, 'tennessee': 2658, 'stuns': 2567, 'ip': 1342, 'outsourcing': 1821, 'spies': 2489, 'lack': 1444, 'device': 711, 'throws': 2691, 'attempt': 165, 'matsushita': 1589, 'dust': 790, 'seed': 2319, 'secrets': 2314, 'broker': 331, 'bug': 342, 'might': 1629, 'czech': 636, 'pieces': 1904, 'popular': 1962, 'qualifier': 2059, 'looms': 1530, 'sri': 2503, 'lanka': 1450, 'chen': 451, 'regulators': 2144, 'contest': 558, 'co': 503, 'total': 2719, 'instant': 1318, 'tap': 2635, 'monza': 1666, 'protect': 2034, 'entry': 851, 'sky': 2425, 'tracks': 2732, 'nod': 1751, 'deny': 692, 'mouse': 1682, 'commission': 526, 'msn': 1691, 'accepts': 6, 'drivers': 778, 'turmoil': 2777, 'buyout': 356, 'tightens': 2700, 'exchange': 879, 'gaming': 1073, 'songs': 2462, 'republicans': 2167, 'eta': 866, 'ea': 793, 'gp': 1128, 'pre': 1984, 'opteron': 1801, 'used': 2828, 'hour': 1249, 'kenteris': 1412, 'thanou': 2676, 'quit': 2072, 'amateur': 73, 'construction': 554, 'execs': 881, 'capacity': 384, 'semis': 2335, 'chapter': 436, 'judging': 1397, 'philadelphia': 1893, 'pride': 1996, 'worry': 2967, 'controls': 565, 'customers': 629, 'meetings': 1602, 'bail': 193, 'mcdonald': 1593, 'abducted': 1, 'lcd': 1472, 'catching': 409, 'earthquakes': 800, 'caught': 410, 'fair': 917, 'allawi': 65, 'escapes': 862, 'approaches': 118, 'trulli': 2767, 'enterprises': 849, 'turnaround': 2779, 'peterson': 1890, 'meter': 1615, 'dhaka': 714, 'assassination': 148, 'headscarf': 1190, 'retires': 2186, 'pledge': 1937, 'qualifying': 2060, 'auditor': 169, 'postal': 1969, 'warnings': 2898, 'university': 2804, 'birthday': 256, 'declares': 665, 'midday': 1627, 'greeks': 1134, 'index': 1298, 'xbox': 2980, 'pick': 1901, 'mercury': 1610, 'ncaa': 1717, 'cycle': 634, 'word': 2958, 'selection': 2326, 'beta': 241, 'insurgents': 1321, 'fixes': 994, 'compromise': 535, 'lifted': 1498, 'proposes': 2032, 'dutch': 791, 'poised': 1946, 'promise': 2028, 'development': 708, 'atomic': 162, 'sight': 2404, 'sharapova': 2369, 'ten': 2657, 'lowe': 1540, 'trails': 2738, 'skype': 2426, 'tuesday': 2770, 'members': 1604, 'john': 1384, 'forest': 1029, 'tense': 2660, 'falluja': 921, 'kick': 1417, 'owner': 1825, 'alaska': 61, 'spark': 2482, 'bridge': 319, 'em': 833, 'postpones': 1971, 'crucial': 613, 'community': 527, 'never': 1735, 'netscape': 1732, 'shrinking': 2395, 'welcome': 2926, 'accord': 9, 'angry': 92, 'thorpe': 2683, 'door': 758, 'doctors': 747, 'standoff': 2513, 'website': 2917, 'executives': 883, 'puerto': 2042, 'candidate': 379, 'glaxo': 1108, 'button': 353, 'electric': 829, 'outbreak': 1816, 'troop': 2759, 'sworn': 2612, 'anderson': 87, 'spirit': 2490, 'ioc': 1341, 'statement': 2522, 'stunned': 2566, 'applied': 115, 'offense': 1774, 'magic': 1553, 'takers': 2627, 'ravaged': 2105, 'yields': 2992} "
     ]
    }
   ],
   "source": [
    "# Print our features\n",
    "\n",
    "features = tfidf_vectorizer.get_feature_names_out()\n",
    "print(tfidf_vectorizer.vocabulary_, end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1d2d50-a90d-4f23-8dd4-fe86285d9b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm feature number\n",
    "\n",
    "print(len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67589178-9134-4c03-83f3-28437806b88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the TF-IDF feature matrices\n",
    "\n",
    "#pd.DataFrame(train_desc_features.toarray()).to_csv(os.path.join(feature_data_dir, 'train_desc_features.csv'), index=False)\n",
    "#pd.DataFrame(test_desc_features.toarray()).to_csv(os.path.join(feature_data_dir, 'test_desc_featuress.csv'), index=False)\n",
    "#pd.DataFrame(train_title_features.toarray()).to_csv(os.path.join(feature_data_dir, 'train_title_features.csv'), index=False)\n",
    "#pd.DataFrame(test_title_features.toarray()).to_csv(os.path.join(feature_data_dir, 'test_title_featuress.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb26fb14-aaca-4d59-a48a-6cf31e68d181",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6f59a9-5f6f-45ec-9033-370d551893f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum the counts of each index\n",
    "class_counts = df_train['Class Index'].value_counts().reset_index()\n",
    "\n",
    "# Visualize class distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=class_counts, x='Class Index', y='count', hue='count')\n",
    "plt.title('Class Distribution')\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5d606f-03f5-479c-a1a3-0df0683ad82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics of class distribution\n",
    "\n",
    "class_balance = class_counts.describe()\n",
    "print(\"Class Balance:\")\n",
    "print(class_balance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b3df77-f6f1-492b-931f-ee7c7c0a3998",
   "metadata": {},
   "source": [
    "Note that there is a fairly even distribution of categories in our training dataset. No further resampling techniques needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3d05a8-1e8e-429e-aa32-cd2a14e7074a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting dataframes by category\n",
    "\n",
    "index_one = df_train['Class Index'] == 1\n",
    "df_index_one = df_train[index_one]\n",
    "\n",
    "index_two = df_train['Class Index'] == 2\n",
    "df_index_two = df_train[index_two]\n",
    "\n",
    "index_three = df_train['Class Index'] == 3\n",
    "df_index_three = df_train[index_three]\n",
    "\n",
    "index_four = df_train['Class Index'] == 4\n",
    "df_index_four = df_train[index_four]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78c74e1-4ad6-4d9f-92a6-fa673799697f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather most common words for category World News\n",
    "\n",
    "index_list_one = ' '.join(df_index_one['Title']).split()\n",
    "word_counts_one = Counter(index_list_one)\n",
    "one_common_words = word_counts_one.most_common(30)\n",
    "print(\"\\nWorld News - Most Common Words:\")\n",
    "print(one_common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf82da8-1fc8-4ac5-bafa-b571b9a24940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather most common words for category Sports News\n",
    "\n",
    "index_list_two = ' '.join(df_index_two['Title']).split()\n",
    "word_counts_two = Counter(index_list_two)\n",
    "two_common_words = word_counts_two.most_common(30)\n",
    "print(\"\\nSports News - Most Common Words:\")\n",
    "print(two_common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f22728-04f9-4f71-9244-b13a7516dba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather most common words for category Business News\n",
    "\n",
    "index_list_three = ' '.join(df_index_three['Title']).split()\n",
    "word_counts_three = Counter(index_list_three)\n",
    "three_common_words = word_counts_three.most_common(30)\n",
    "print(\"\\nBusiness News - Most Common Words:\")\n",
    "print(three_common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca417e78-dd27-48c2-a3a0-f9e348b8ecc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather most common words for category Sci/Tech News\n",
    "\n",
    "index_list_four = ' '.join(df_index_four['Title']).split()\n",
    "word_counts_four = Counter(index_list_four)\n",
    "four_common_words = word_counts_four.most_common(30)\n",
    "print(\"\\nSci/Tech News - Most Common Words:\")\n",
    "print(four_common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8842160-1fad-45f1-ab26-0cafea59480a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vizualize word frequency for World News\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=[word[0] for word in one_common_words], y=[word[1] for word in one_common_words])\n",
    "plt.title('Most Common Words in World News')\n",
    "plt.xlabel('Word')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(rotation=60)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee790b42-4992-44da-a93a-dbee6d57cd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vizualize word frequency for Business News\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=[word[0] for word in two_common_words], y=[word[1] for word in two_common_words])\n",
    "plt.title('Most Common Words in Sports News')\n",
    "plt.xlabel('Word')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(rotation=60)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6f658c-d81c-4944-a07b-0e094e13a90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vizualize word frequency for World News\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=[word[0] for word in three_common_words], y=[word[1] for word in three_common_words])\n",
    "plt.title('Most Common Words in Business News')\n",
    "plt.xlabel('Word')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(rotation=60)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe884d1-73f1-40be-a1a9-e6554a224ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vizualize word frequency for World News\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=[word[0] for word in four_common_words], y=[word[1] for word in four_common_words])\n",
    "plt.title('Most Common Words in Sci/Tech News')\n",
    "plt.xlabel('Word')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(rotation=60)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "316c286c-7fc0-4c5f-90d7-e36a56f1d34d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17443     3\n",
      "2145      7\n",
      "16657     6\n",
      "26299     6\n",
      "25590     4\n",
      "         ..\n",
      "29802     6\n",
      "5390     11\n",
      "860       4\n",
      "15795     4\n",
      "23654     5\n",
      "Name: Title Length, Length: 25500, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Get title lengths for each row\n",
    "df_train['Title Length'] = df_train['Title'].apply(lambda x: len(x.split()))\n",
    "print(df_train['Title Length'])\n",
    "\n",
    "# Modifying df_test for future use\n",
    "df_test['Title Length'] = df_test['Title'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b3a8cd83-049e-4827-88bb-1abc667f7a48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Title length analysis\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df_train['Title Length'], bins=10)\n",
    "plt.title('Distribution of Title Lengths')\n",
    "plt.xlabel('Title Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b2092d-8b39-4af7-87d8-f68dae1ac8f6",
   "metadata": {},
   "source": [
    "Note that the distribution of our title lengths is right-skew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2596f239-a78f-42a0-a423-c89efab83248",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get TF IDF values as a dataframe\n",
    "\n",
    "tfidf_df = pd.DataFrame(train_title_features.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2648438c-becc-40db-a7d2-b8bb1a03fd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform matrix to array, flatten, and removes zeros\n",
    "\n",
    "tfidf_df = train_title_features.toarray().flatten()\n",
    "tfidf_df = tfidf_df[tfidf_df != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205b3bb2-d7a4-4997-91dc-e345bd828a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of non-zero TF-IDF Scores\n",
    "\n",
    "sns.histplot(tfidf_df, bins=10, kde=True)\n",
    "plt.xlabel(\"TF-IDF Score\")\n",
    "plt.ylabel(\"Number of Words\")\n",
    "plt.title(\"Distribution of TF-IDF Scores in the Corpus\")\n",
    "plt.xticks(rotation=45)  # Optional: Rotate x-axis labels for long feature names\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30cf47b-7428-4762-a44a-33451f69311d",
   "metadata": {},
   "source": [
    "Note that our TF IDF distribution is right skew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d716a021-67be-41b5-8911-5c1c18825a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_engine.outliers import Winsorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cf7fae-fe84-432d-af5f-b9537b9903f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot boxplot to find skewness\n",
    "\n",
    "sns.boxplot(df_train['Title Length'], orient='h')\n",
    "plt.xlabel(\"Title Length\")\n",
    "plt.title(\"Boxplot of Title Length\")  # Optional: Rotate x-axis labels for long feature names\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400d895e-0bd3-4d4c-9c0f-44d482f59bf0",
   "metadata": {},
   "source": [
    "Confirms previous image indicating right skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a261c00-1a44-45f9-ae10-d6369a59d128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Winsorize the text length to handle outliers\n",
    "\n",
    "capper = Winsorizer(capping_method='gaussian', tail='right', fold=2)\n",
    "capper.fit(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da52d1d-ccd4-4de8-b373-97da9f592f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "capper.right_tail_caps_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67976cd-7084-454b-a860-a473e0fe3be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_t = capper.transform(df_train)\n",
    "test_t = capper.transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66974e4b-4c06-41db-a76d-526c7ad7a487",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(train_t['Title Length'], orient='h')\n",
    "plt.xlabel(\"Title Length\")\n",
    "plt.title(\"Boxplot of Title Length\")  # Optional: Rotate x-axis labels for long feature names\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4c64f6-9f1e-4f33-aa48-d90f45e8807e",
   "metadata": {},
   "source": [
    "Outliers are no longer present in dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04017ae8-e72c-4e2b-ae4d-123d7dc15f5b",
   "metadata": {},
   "source": [
    "# Transformer Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aa103aba-e341-4212-b17f-b3aee15b5d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Embedding, Dense, Dropout, GlobalAveragePooling1D, LayerNormalization, MultiHeadAttention\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ed68d04e-01a6-443a-9cd9-6e45e2b49518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\"> Layer (type)                  </span><span style=\"font-weight: bold\"> Output Shape              </span><span style=\"font-weight: bold\">         Param # </span><span style=\"font-weight: bold\"> Connected to               </span>\n",
       "\n",
       " input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                          \n",
       "\n",
       " embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280,000</span>  input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                \n",
       "\n",
       " add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
       "\n",
       " multi_head_attention           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">527,488</span>  add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)                                                                                  \n",
       "\n",
       " dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  multi_head_attention[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       "\n",
       " add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       "\n",
       " layer_normalization            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                       <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>  add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)                                                                                  \n",
       "\n",
       " dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span>  layer_normalization[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
       "\n",
       " dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">65,664</span>  dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                \n",
       "\n",
       " dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              \n",
       "\n",
       " add_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  layer_normalization[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], \n",
       "                                                                            dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
       "\n",
       " layer_normalization_1          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                       <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>  add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)                                                                                  \n",
       "\n",
       " multi_head_attention_1         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">527,488</span>  layer_normalization_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)                                                       layer_normalization_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n",
       "\n",
       " dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  multi_head_attention_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       "\n",
       " add_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  layer_normalization_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n",
       "                                                                            dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
       "\n",
       " layer_normalization_2          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                       <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>  add_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)                                                                                  \n",
       "\n",
       " dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span>  layer_normalization_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n",
       "\n",
       " dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">65,664</span>  dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              \n",
       "\n",
       " dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              \n",
       "\n",
       " add_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  layer_normalization_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n",
       "                                                                            dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
       "\n",
       " layer_normalization_3          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                       <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>  add_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)                                                                                  \n",
       "\n",
       " multi_head_attention_2         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">527,488</span>  layer_normalization_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)                                                       layer_normalization_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n",
       "\n",
       " dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  multi_head_attention_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       "\n",
       " add_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  layer_normalization_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n",
       "                                                                            dropout_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
       "\n",
       " layer_normalization_4          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                       <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>  add_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)                                                                                  \n",
       "\n",
       " dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span>  layer_normalization_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n",
       "\n",
       " dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">65,664</span>  dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              \n",
       "\n",
       " dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  dense_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              \n",
       "\n",
       " add_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  layer_normalization_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n",
       "                                                                            dropout_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
       "\n",
       " layer_normalization_5          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                       <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>  add_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)                                                                                  \n",
       "\n",
       " multi_head_attention_3         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">527,488</span>  layer_normalization_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)                                                       layer_normalization_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n",
       "\n",
       " dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  multi_head_attention_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       "\n",
       " add_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  layer_normalization_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n",
       "                                                                            dropout_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           \n",
       "\n",
       " layer_normalization_6          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                       <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>  add_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)                                                                                  \n",
       "\n",
       " dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span>  layer_normalization_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n",
       "\n",
       " dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">65,664</span>  dense_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              \n",
       "\n",
       " dropout_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  dense_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              \n",
       "\n",
       " add_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  layer_normalization_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n",
       "                                                                            dropout_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           \n",
       "\n",
       " layer_normalization_7          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                       <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>  add_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)                                                                                  \n",
       "\n",
       " global_average_pooling1d       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  layer_normalization_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)                                                                              \n",
       "\n",
       " dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                              <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span>  global_average_pooling1d[<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       " input (\u001b[38;5;33mInputLayer\u001b[0m)             (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                              \u001b[38;5;34m0\u001b[0m  -                          \n",
       "\n",
       " embedding (\u001b[38;5;33mEmbedding\u001b[0m)          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 \u001b[38;5;34m1,280,000\u001b[0m  input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                \n",
       "\n",
       " add (\u001b[38;5;33mAdd\u001b[0m)                      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)                         \u001b[38;5;34m0\u001b[0m  embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
       "\n",
       " multi_head_attention           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)                   \u001b[38;5;34m527,488\u001b[0m  add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       " (\u001b[38;5;33mMultiHeadAttention\u001b[0m)                                                                                  \n",
       "\n",
       " dropout_1 (\u001b[38;5;33mDropout\u001b[0m)            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)                         \u001b[38;5;34m0\u001b[0m  multi_head_attention[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
       "\n",
       " add_1 (\u001b[38;5;33mAdd\u001b[0m)                    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)                         \u001b[38;5;34m0\u001b[0m  add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
       "\n",
       " layer_normalization            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)                       \u001b[38;5;34m256\u001b[0m  add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                \n",
       " (\u001b[38;5;33mLayerNormalization\u001b[0m)                                                                                  \n",
       "\n",
       " dense (\u001b[38;5;33mDense\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)                    \u001b[38;5;34m66,048\u001b[0m  layer_normalization[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
       "\n",
       " dense_1 (\u001b[38;5;33mDense\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)                    \u001b[38;5;34m65,664\u001b[0m  dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                \n",
       "\n",
       " dropout_2 (\u001b[38;5;33mDropout\u001b[0m)            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)                         \u001b[38;5;34m0\u001b[0m  dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              \n",
       "\n",
       " add_2 (\u001b[38;5;33mAdd\u001b[0m)                    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)                         \u001b[38;5;34m0\u001b[0m  layer_normalization[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], \n",
       "                                                                            dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
       "\n",
       " layer_normalization_1          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)                       \u001b[38;5;34m256\u001b[0m  add_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                \n",
       " (\u001b[38;5;33mLayerNormalization\u001b[0m)                                                                                  \n",
       "\n",
       " multi_head_attention_1         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)                   \u001b[38;5;34m527,488\u001b[0m  layer_normalization_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m\u001b[0m \n",
       " (\u001b[38;5;33mMultiHeadAttention\u001b[0m)                                                       layer_normalization_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m\u001b[0m \n",
       "\n",
       " dropout_4 (\u001b[38;5;33mDropout\u001b[0m)            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)                         \u001b[38;5;34m0\u001b[0m  multi_head_attention_1[\u001b[38;5;34m0\u001b[0m] \n",
       "\n",
       " add_3 (\u001b[38;5;33mAdd\u001b[0m)                    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)                         \u001b[38;5;34m0\u001b[0m  layer_normalization_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m\u001b[0m \n",
       "                                                                            dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
       "\n",
       " layer_normalization_2          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)                       \u001b[38;5;34m256\u001b[0m  add_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                \n",
       " (\u001b[38;5;33mLayerNormalization\u001b[0m)                                                                                  \n",
       "\n",
       " dense_2 (\u001b[38;5;33mDense\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)                    \u001b[38;5;34m66,048\u001b[0m  layer_normalization_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m\u001b[0m \n",
       "\n",
       " dense_3 (\u001b[38;5;33mDense\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)                    \u001b[38;5;34m65,664\u001b[0m  dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              \n",
       "\n",
       " dropout_5 (\u001b[38;5;33mDropout\u001b[0m)            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)                         \u001b[38;5;34m0\u001b[0m  dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              \n",
       "\n",
       " add_4 (\u001b[38;5;33mAdd\u001b[0m)                    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)                         \u001b[38;5;34m0\u001b[0m  layer_normalization_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m\u001b[0m \n",
       "                                                                            dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
       "\n",
       " layer_normalization_3          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)                       \u001b[38;5;34m256\u001b[0m  add_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                \n",
       " (\u001b[38;5;33mLayerNormalization\u001b[0m)                                                                                  \n",
       "\n",
       " multi_head_attention_2         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)                   \u001b[38;5;34m527,488\u001b[0m  layer_normalization_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m\u001b[0m \n",
       " (\u001b[38;5;33mMultiHeadAttention\u001b[0m)                                                       layer_normalization_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m\u001b[0m \n",
       "\n",
       " dropout_7 (\u001b[38;5;33mDropout\u001b[0m)            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)                         \u001b[38;5;34m0\u001b[0m  multi_head_attention_2[\u001b[38;5;34m0\u001b[0m] \n",
       "\n",
       " add_5 (\u001b[38;5;33mAdd\u001b[0m)                    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)                         \u001b[38;5;34m0\u001b[0m  layer_normalization_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m\u001b[0m \n",
       "                                                                            dropout_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
       "\n",
       " layer_normalization_4          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)                       \u001b[38;5;34m256\u001b[0m  add_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                \n",
       " (\u001b[38;5;33mLayerNormalization\u001b[0m)                                                                                  \n",
       "\n",
       " dense_4 (\u001b[38;5;33mDense\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)                    \u001b[38;5;34m66,048\u001b[0m  layer_normalization_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m\u001b[0m \n",
       "\n",
       " dense_5 (\u001b[38;5;33mDense\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)                    \u001b[38;5;34m65,664\u001b[0m  dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              \n",
       "\n",
       " dropout_8 (\u001b[38;5;33mDropout\u001b[0m)            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)                         \u001b[38;5;34m0\u001b[0m  dense_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              \n",
       "\n",
       " add_6 (\u001b[38;5;33mAdd\u001b[0m)                    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)                         \u001b[38;5;34m0\u001b[0m  layer_normalization_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m\u001b[0m \n",
       "                                                                            dropout_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
       "\n",
       " layer_normalization_5          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)                       \u001b[38;5;34m256\u001b[0m  add_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                \n",
       " (\u001b[38;5;33mLayerNormalization\u001b[0m)                                                                                  \n",
       "\n",
       " multi_head_attention_3         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)                   \u001b[38;5;34m527,488\u001b[0m  layer_normalization_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m\u001b[0m \n",
       " (\u001b[38;5;33mMultiHeadAttention\u001b[0m)                                                       layer_normalization_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m\u001b[0m \n",
       "\n",
       " dropout_10 (\u001b[38;5;33mDropout\u001b[0m)           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)                         \u001b[38;5;34m0\u001b[0m  multi_head_attention_3[\u001b[38;5;34m0\u001b[0m] \n",
       "\n",
       " add_7 (\u001b[38;5;33mAdd\u001b[0m)                    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)                         \u001b[38;5;34m0\u001b[0m  layer_normalization_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m\u001b[0m \n",
       "                                                                            dropout_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           \n",
       "\n",
       " layer_normalization_6          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)                       \u001b[38;5;34m256\u001b[0m  add_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                \n",
       " (\u001b[38;5;33mLayerNormalization\u001b[0m)                                                                                  \n",
       "\n",
       " dense_6 (\u001b[38;5;33mDense\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)                    \u001b[38;5;34m66,048\u001b[0m  layer_normalization_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m\u001b[0m \n",
       "\n",
       " dense_7 (\u001b[38;5;33mDense\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)                    \u001b[38;5;34m65,664\u001b[0m  dense_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              \n",
       "\n",
       " dropout_11 (\u001b[38;5;33mDropout\u001b[0m)           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)                         \u001b[38;5;34m0\u001b[0m  dense_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              \n",
       "\n",
       " add_8 (\u001b[38;5;33mAdd\u001b[0m)                    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)                         \u001b[38;5;34m0\u001b[0m  layer_normalization_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m\u001b[0m \n",
       "                                                                            dropout_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           \n",
       "\n",
       " layer_normalization_7          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)                       \u001b[38;5;34m256\u001b[0m  add_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                \n",
       " (\u001b[38;5;33mLayerNormalization\u001b[0m)                                                                                  \n",
       "\n",
       " global_average_pooling1d       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                              \u001b[38;5;34m0\u001b[0m  layer_normalization_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m\u001b[0m \n",
       " (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)                                                                              \n",
       "\n",
       " dense_8 (\u001b[38;5;33mDense\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                              \u001b[38;5;34m129\u001b[0m  global_average_pooling1d[\u001b[38;5;34m\u001b[0m \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,918,977</span> (14.95 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,918,977\u001b[0m (14.95 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,918,977</span> (14.95 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,918,977\u001b[0m (14.95 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Positional Encoding\n",
    "def get_positional_encoding(seq_length, d_model):\n",
    "    positions = tf.range(seq_length, dtype=tf.float32)[:, tf.newaxis]\n",
    "    i = tf.range(d_model, dtype=tf.float32)[tf.newaxis, :]\n",
    "    angle_rates = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "    angle_rads = positions * angle_rates\n",
    "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "    pos_encoding = tf.concat([sines, cosines], axis=-1)\n",
    "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "    return pos_encoding\n",
    "\n",
    "\n",
    "def transformer_block(x, num_heads, d_model, dff, rate, training):\n",
    "    attn_output = MultiHeadAttention(num_heads=num_heads, key_dim=d_model)(x, x)\n",
    "    attn_output = Dropout(rate)(attn_output, training=training)\n",
    "    out1 = LayerNormalization(epsilon=1e-6)(x + attn_output)\n",
    "    ffn_output = Dense(dff, activation='relu')(out1)\n",
    "    ffn_output = Dense(d_model)(ffn_output)\n",
    "    ffn_output = Dropout(rate)(ffn_output, training=training)\n",
    "    return LayerNormalization(epsilon=1e-6)(out1 + ffn_output)\n",
    "\n",
    "\n",
    "# Build the Transformer Model for Text Classification\n",
    "def build_model(max_len_input, vocab_size, num_heads=8, d_model=128, dff=512, rate=0.1):\n",
    "    # Input\n",
    "    inputs = Input(shape=(max_len_input,), name=\"input\")\n",
    "    embedding = Embedding(vocab_size, d_model, name=\"embedding\")(inputs)\n",
    "    pos_encoding = get_positional_encoding(max_len_input, d_model)\n",
    "    embedding += pos_encoding\n",
    "\n",
    "    # Transformer Encoder\n",
    "    encoder_output = embedding\n",
    "    for _ in range(4):\n",
    "        encoder_output = transformer_block(encoder_output, num_heads, d_model, dff, rate, training=True)\n",
    "\n",
    "    # Global Average Pooling\n",
    "    pooled_output = GlobalAveragePooling1D()(encoder_output)\n",
    "\n",
    "    # Output layer\n",
    "    outputs = Dense(1, activation=\"sigmoid\")(pooled_output)  # Binary classification, use sigmoid activation\n",
    "\n",
    "    # Define the model\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])  # Binary classification, use binary_crossentropy\n",
    "\n",
    "    return model\n",
    "\n",
    "# Parameters\n",
    "max_len_input = 100\n",
    "vocab_size = 10000\n",
    "\n",
    "# Create the model\n",
    "model = build_model(max_len_input, vocab_size)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c4b49de8-f13e-48ae-a68b-806ad1bbf227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "def preprocess_data(input_text, tokenizer, max_len_input):\n",
    "    # Tokenize and encode input text\n",
    "    input_ids = tokenizer.encode(input_text, max_length=max_len_input, truncation=True)\n",
    "    input_ids_padded = input_ids + [0] * (max_len_input - len(input_ids))  # Pad sequences\n",
    "    return input_ids_padded\n",
    "def predict_class(input_text, tokenizer, model, max_len_input):\n",
    "    input_ids_padded = preprocess_data(input_text, tokenizer, max_len_input)\n",
    "    # Convert input to tensor\n",
    "    input_ids_tensor = tf.convert_to_tensor([input_ids_padded])\n",
    "    # Predict using the model\n",
    "    outputs = model(input_ids_tensor)\n",
    "    predicted_class = tf.argmax(outputs[0]).numpy()\n",
    "    return predicted_class\n",
    "\n",
    "predicted_class = predict_class(\"The US is in running out of oil\", tokenizer, model, max_len_input)\n",
    "print(predicted_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68f56e4b-e70f-4113-82e8-622486c21bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForMaskedLM, BertTokenizer, TrainingArguments, TFBertForTokenClassification\n",
    "from keras.losses import SparseCategoricalCrossentropy\n",
    "import tftrainer\n",
    "import torch\n",
    "from transformers import DistilBertForSequenceClassification, AutoModelForSequenceClassification, AutoTokenizer\n",
    "from torch import cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5aeb7653-d249-457e-a618-68cb895ee95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "31303f70-a2f5-4d1b-a8c2-55d1d12b9419",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=4, problem_type=\"multi_label_classification\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "30d8af2f-dc27-4ecf-811d-3531dd112457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example DistilBert\n",
    "\n",
    "max_length=20\n",
    "inputs = tokenizer(\"Hello, my dog is cute\", padding='longest', max_length=max_length, return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e1197f8c-1b22-42db-9021-cca88fe1478c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0112,  0.0161,  0.1391,  0.0291]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print logits\n",
    "\n",
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b41a3c4e-ae0c-4725-a210-3324bacf7d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "# Print predicted class IDs\n",
    "\n",
    "predicted_class_ids = torch.arange(0, logits.shape[-1])[torch.sigmoid(logits).squeeze(dim=0) > 0.5]\n",
    "print(predicted_class_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4396fa15-99a4-4150-b2ef-5f4097ece5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = torch.sum(\n",
    "    torch.nn.functional.one_hot(predicted_class_ids[None, :].clone(), num_classes=4), dim=1\n",
    ").to(torch.float)\n",
    "loss = model(**inputs, labels=labels).loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8d7b30eb-4548-46ea-ab46-fcf413e748a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 1., 1.]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cfdc2319-4b00-4479-83b6-50c6b6bc70b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6694, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a551d831-a9b1-4621-9dd5-036207c9fb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbert_train_x = df_train.iloc[:,1:]\n",
    "dbert_val_x = df_test.iloc[:,1:]\n",
    "dbert_train_y = df_train.iloc[:,:1] \n",
    "dbert_val_y = df_test.iloc[:,:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5f24d9cd-9dc2-4a1d-92c1-4b8e4b483981",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_y = dbert_val_y.squeeze().tolist()\n",
    "train_x = dbert_train_x.astype('str').squeeze().tolist()\n",
    "val_x = dbert_val_x.astype('str').squeeze().tolist()\n",
    "train_y = dbert_train_y.squeeze().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "82cc4f91-43cc-40d8-8bf5-54187e59b65e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_x_encoded = tokenizer(train_x, padding='longest', max_length=max_length, return_tensors=\"pt\")\n",
    "val_x_encoded = tokenizer(val_x, padding='longest', max_length=max_length, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "62f53b86-62e9-42bb-8cda-40af5b2ebbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(data, batch_size):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(data)\n",
    "    dataset = dataset.map(lambda x: {key: tf.reshape(val, [-1]) for key, val in x.items()})\n",
    "    dataset = dataset.shuffle(buffer_size=10000).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bc0ce691-48d5-4199-9cee-1cfa7ed246bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Attempt to convert a value (Encoding(num_tokens=22, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])) with an unsupported type (<class 'tokenizers.Encoding'>) to a Tensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[81], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Convert tensor slice to full tensor\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m full_train \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_x_encoded\u001b[49m\u001b[43m,\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mconcat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\OneDrive\\Documents\\GitHub\\generative-ai-text-summarization\\config\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\OneDrive\\Documents\\GitHub\\generative-ai-text-summarization\\config\\Lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:108\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    106\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[0;32m    107\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: Attempt to convert a value (Encoding(num_tokens=22, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])) with an unsupported type (<class 'tokenizers.Encoding'>) to a Tensor."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7dce9a3a-b1cb-4101-89c3-632e9e623756",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(train_x_encoded),\n",
    "    train_y\n",
    "))\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(val_x_encoded),\n",
    "    val_y\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7064e4a3-4804-4415-9c45-d8fd4c69b96b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TensorSliceDataset element_spec=({'input_ids': TensorSpec(shape=(22,), dtype=tf.int64, name=None), 'attention_mask': TensorSpec(shape=(22,), dtype=tf.int64, name=None)}, TensorSpec(shape=(), dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "883179a0-6f48-4ec5-a4f1-9635e16a5fe6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          \n",
    "    num_train_epochs=3,              \n",
    "    per_device_train_batch_size=16,  \n",
    "    per_device_eval_batch_size=64,   \n",
    "    warmup_steps=500,                \n",
    "    weight_decay=1e-5,               \n",
    "    logging_dir='./logs',            \n",
    "    eval_steps=100                   \n",
    ")\n",
    "\n",
    "trainer = transformers.Trainer(model=model,\n",
    "                args=training_args,\n",
    "                train_dataset=train_dataset,\n",
    "                eval_dataset=val_dataset,\n",
    "                compute_metrics='sparsecategoricalcrossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9bf09413-a02a-47bb-80dc-3926af0c6e9e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'_TensorSliceDataset' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[70], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\OneDrive\\Documents\\GitHub\\generative-ai-text-summarization\\config\\Lib\\site-packages\\transformers\\trainer.py:1859\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1857\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   1858\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1860\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1861\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1862\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1864\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\OneDrive\\Documents\\GitHub\\generative-ai-text-summarization\\config\\Lib\\site-packages\\transformers\\trainer.py:2165\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2162\u001b[0m     rng_to_sync \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   2164\u001b[0m step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 2165\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mepoch_iterator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   2166\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtotal_batched_samples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[0;32m   2168\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minclude_num_input_tokens_seen\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[1;32m~\\OneDrive\\Documents\\GitHub\\generative-ai-text-summarization\\config\\Lib\\site-packages\\accelerate\\data_loader.py:452\u001b[0m, in \u001b[0;36mDataLoaderShard.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;66;03m# We iterate one batch ahead to check when we are at the end\u001b[39;00m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 452\u001b[0m     current_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n",
      "File \u001b[1;32m~\\OneDrive\\Documents\\GitHub\\generative-ai-text-summarization\\config\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\OneDrive\\Documents\\GitHub\\generative-ai-text-summarization\\config\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\OneDrive\\Documents\\GitHub\\generative-ai-text-summarization\\config\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\OneDrive\\Documents\\GitHub\\generative-ai-text-summarization\\config\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "\u001b[1;31mTypeError\u001b[0m: '_TensorSliceDataset' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fcc73bbb-57af-483a-9d79-32070044f6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(learning_rate = 1e-5)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c5bc69-e38a-47d2-a57a-c197d913cb92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
