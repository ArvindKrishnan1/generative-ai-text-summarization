{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1224ff1-aeff-4e29-b202-481832e55ab0",
   "metadata": {},
   "source": [
    "# Generative AI Text Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882e6f12-da61-4f0b-ab64-3526080a77b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import opendatasets as od\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import s3fs\n",
    "import fs_s3fs\n",
    "import fsspec\n",
    "import json\n",
    "from llama_index.core import TreeIndex, SimpleDirectoryReader\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import transformers\n",
    "import mlflow\n",
    "import hyperopt as hp\n",
    "import sphinx\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbad013-ca4e-4666-9764-f040416cb0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download stopwords\n",
    "\n",
    "#nltk.download('stopwords')\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "newStopwords = ['b','lt','gt','n','u'] # Add stopwords \n",
    "\n",
    "for stopword in newStopwords:\n",
    "    stopwords.append(stopword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43282ff1-8419-4736-86e3-cfd2c3a008d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762117e8-eeaf-45ea-98d6-4bbfca6447d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648def37-b389-46cd-a7d8-a0344a83439a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dataset from Kaggle\n",
    "\n",
    "dataset = \"https://www.kaggle.com/datasets/amananandrai/ag-news-classification-dataset/data\"\n",
    "od.download(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f5b57f-b8de-46d5-a7fd-f5de9f7b5573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read dataset, import only 30000 rows of data\n",
    "\n",
    "df = pd.read_csv(r'C:\\Users\\nickr\\OneDrive\\Documents\\GitHub\\generative-ai-text-summarization\\data\\ag-news-classification-dataset\\ag_news.csv',nrows=30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ceb048-4a45-4b4e-ad52-44b5918d6dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check shape of dataframe\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f506ecfc-e26c-4ecb-9469-1ee0567b8621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change Class Index to categorical variable\n",
    "\n",
    "df['Class Index']=df['Class Index'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7925624a-4c1d-4927-808f-5975d06b0384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm importation\n",
    "\n",
    "df.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53803b54-f203-406b-9cfc-3931fa943371",
   "metadata": {},
   "source": [
    "# Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d737225c-a1f0-4109-abde-5c2d75506d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find null values and datatypes\n",
    "\n",
    "df.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be72a3e-3d19-4901-abdb-7fa1006122fb",
   "metadata": {},
   "source": [
    "There are no null values in the df_train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6816ed8-6b16-4f5a-8e8f-86c6745b22ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for duplicates\n",
    "\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8028175-62cd-4820-a191-1e6ae3652326",
   "metadata": {},
   "source": [
    "There are no duplicate values in the df_train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc8c488-1f0f-4f07-bf1a-93b1e604194e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning data set html, special, and non-textual characters\n",
    "\n",
    "def cleaning_text(text):\n",
    "    # Remove HTML tags\n",
    "    cleaning_text = re.sub('<.*?>', '', text)\n",
    "    # Remove special characters and non-textual \n",
    "    cleaning_text = re.sub(r'([^a-zA-Z\\s]|\\\\b[A-Za-z] \\\\b|\\\\b [A-Za-z]\\\\b)', ' ', cleaning_text) # checks plain text for given characters\n",
    "    return cleaning_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1479d5c2-b4e2-4c30-9faf-3051b423d117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply text cleaning to text in both Description and Title\n",
    "\n",
    "df['Title'] = df['Title'].apply(cleaning_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5a1d06-2735-4db7-86ec-acc992362765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that the function worked\n",
    "\n",
    "df.head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518814df-08e0-40e6-8b97-f87cbc98e8e9",
   "metadata": {},
   "source": [
    "Note that in this data set, 1 represents World News, 2 represents Sports News, 3 represents Business News, and 4 represents Sci/Tech news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0223382e-0fd0-4e2a-a2ce-58bf02a2b5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to remove stop words\n",
    "\n",
    "stop_words = set(stopwords)\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text.lower())  # Tokenization and lowercasing\n",
    "    tokens = [word for word in tokens if word not in stop_words]  # Stop word removal\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904e8790-b96c-4391-96c5-1ceb2209ee41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply preprocessing to text in Title\n",
    "\n",
    "df['Title'] = df['Title'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85872e09-1b0f-4991-9337-10ffec72a040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that the function worked\n",
    "\n",
    "df.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e870c4d-abfd-4af9-b3e3-200b57aea54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to CSV for ease of use in future\n",
    "\n",
    "cleaned_data_file = r'C:\\Users\\nickr\\OneDrive\\Desktop\\CapstoneTechX\\ag_news_cleaned\\cleaned_ag_news.csv'\n",
    "df.to_csv(cleaned_data_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51cd8cdb-add6-4426-84db-803400bbc1f3",
   "metadata": {},
   "source": [
    "# Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d4286e-9003-4783-b52f-b2a3754fbd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training data into training and validation data \n",
    "\n",
    "df_train, df_test = train_test_split(df, test_size=.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d183cea1-30ce-46b1-9a88-60e5a0dcb957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create csv file for train and test data\n",
    "\n",
    "df_train.to_csv(os.path.join(r'C:\\Users\\nickr\\OneDrive\\Desktop\\CapstoneTechX\\ag_news_cleaned', 'train.csv'), index=False)\n",
    "df_test.to_csv(os.path.join(r'C:\\Users\\nickr\\OneDrive\\Desktop\\CapstoneTechX\\ag_news_cleaned', 'test.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcfdf86-2d73-4a16-83bf-292849e06163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature data directory\n",
    "\n",
    "feature_data_dir = r'C:\\Users\\nickr\\OneDrive\\Desktop\\CapstoneTechX\\features'\n",
    "os.makedirs(feature_data_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d65b5e-2da9-43bf-a4ee-12528882de24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF Vectorization for Title\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=3000)  # we can play around with this. This was an arbitrary value\n",
    "train_title_features = tfidf_vectorizer.fit_transform(df_train['Title'])\n",
    "test_title_features = tfidf_vectorizer.transform(df_test['Title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7305e5a-8503-47ef-9a90-d9111b0a741b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at one of the matrices the vectorizer produces\n",
    "\n",
    "# print(df_train['Title'][98])\n",
    "# print(train_title_features.toarray()[98]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c8896a-912f-4ae6-93e7-bcc49eb426ac",
   "metadata": {},
   "source": [
    "Note, the vectorizer produces a value for a specific word on a scale of 0 to 1. The closer the number is to 1, the more unique that word is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371fd926-9565-407d-b609-d86be6844fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print our features\n",
    "\n",
    "features = tfidf_vectorizer.get_feature_names_out()\n",
    "print(tfidf_vectorizer.vocabulary_, end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1d2d50-a90d-4f23-8dd4-fe86285d9b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm feature number\n",
    "\n",
    "print(len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67589178-9134-4c03-83f3-28437806b88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the TF-IDF feature matrices\n",
    "\n",
    "#pd.DataFrame(train_desc_features.toarray()).to_csv(os.path.join(feature_data_dir, 'train_desc_features.csv'), index=False)\n",
    "#pd.DataFrame(test_desc_features.toarray()).to_csv(os.path.join(feature_data_dir, 'test_desc_featuress.csv'), index=False)\n",
    "#pd.DataFrame(train_title_features.toarray()).to_csv(os.path.join(feature_data_dir, 'train_title_features.csv'), index=False)\n",
    "#pd.DataFrame(test_title_features.toarray()).to_csv(os.path.join(feature_data_dir, 'test_title_featuress.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb26fb14-aaca-4d59-a48a-6cf31e68d181",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6f59a9-5f6f-45ec-9033-370d551893f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum the counts of each index\n",
    "class_counts = df_train['Class Index'].value_counts().reset_index()\n",
    "\n",
    "# Visualize class distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=class_counts, x='Class Index', y='count', hue='count')\n",
    "plt.title('Class Distribution')\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5d606f-03f5-479c-a1a3-0df0683ad82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics of class distribution\n",
    "\n",
    "class_balance = class_counts.describe()\n",
    "print(\"Class Balance:\")\n",
    "print(class_balance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b3df77-f6f1-492b-931f-ee7c7c0a3998",
   "metadata": {},
   "source": [
    "Note that there is a fairly even distribution of categories in our training dataset. No further resampling techniques needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3d05a8-1e8e-429e-aa32-cd2a14e7074a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting dataframes by category\n",
    "\n",
    "index_one = df_train['Class Index'] == 1\n",
    "df_index_one = df_train[index_one]\n",
    "\n",
    "index_two = df_train['Class Index'] == 2\n",
    "df_index_two = df_train[index_two]\n",
    "\n",
    "index_three = df_train['Class Index'] == 3\n",
    "df_index_three = df_train[index_three]\n",
    "\n",
    "index_four = df_train['Class Index'] == 4\n",
    "df_index_four = df_train[index_four]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78c74e1-4ad6-4d9f-92a6-fa673799697f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather most common words for category World News\n",
    "\n",
    "index_list_one = ' '.join(df_index_one['Title']).split()\n",
    "word_counts_one = Counter(index_list_one)\n",
    "one_common_words = word_counts_one.most_common(30)\n",
    "print(\"\\nWorld News - Most Common Words:\")\n",
    "print(one_common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf82da8-1fc8-4ac5-bafa-b571b9a24940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather most common words for category Sports News\n",
    "\n",
    "index_list_two = ' '.join(df_index_two['Title']).split()\n",
    "word_counts_two = Counter(index_list_two)\n",
    "two_common_words = word_counts_two.most_common(30)\n",
    "print(\"\\nSports News - Most Common Words:\")\n",
    "print(two_common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f22728-04f9-4f71-9244-b13a7516dba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather most common words for category Business News\n",
    "\n",
    "index_list_three = ' '.join(df_index_three['Title']).split()\n",
    "word_counts_three = Counter(index_list_three)\n",
    "three_common_words = word_counts_three.most_common(30)\n",
    "print(\"\\nBusiness News - Most Common Words:\")\n",
    "print(three_common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca417e78-dd27-48c2-a3a0-f9e348b8ecc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather most common words for category Sci/Tech News\n",
    "\n",
    "index_list_four = ' '.join(df_index_four['Title']).split()\n",
    "word_counts_four = Counter(index_list_four)\n",
    "four_common_words = word_counts_four.most_common(30)\n",
    "print(\"\\nSci/Tech News - Most Common Words:\")\n",
    "print(four_common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8842160-1fad-45f1-ab26-0cafea59480a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vizualize word frequency for World News\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=[word[0] for word in one_common_words], y=[word[1] for word in one_common_words])\n",
    "plt.title('Most Common Words in World News')\n",
    "plt.xlabel('Word')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(rotation=60)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee790b42-4992-44da-a93a-dbee6d57cd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vizualize word frequency for Business News\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=[word[0] for word in two_common_words], y=[word[1] for word in two_common_words])\n",
    "plt.title('Most Common Words in Sports News')\n",
    "plt.xlabel('Word')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(rotation=60)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6f658c-d81c-4944-a07b-0e094e13a90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vizualize word frequency for World News\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=[word[0] for word in three_common_words], y=[word[1] for word in three_common_words])\n",
    "plt.title('Most Common Words in Business News')\n",
    "plt.xlabel('Word')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(rotation=60)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe884d1-73f1-40be-a1a9-e6554a224ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vizualize word frequency for World News\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=[word[0] for word in four_common_words], y=[word[1] for word in four_common_words])\n",
    "plt.title('Most Common Words in Sci/Tech News')\n",
    "plt.xlabel('Word')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(rotation=60)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316c286c-7fc0-4c5f-90d7-e36a56f1d34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get title lengths for each row\n",
    "df_train['Title Length'] = df_train['Title'].apply(lambda x: len(x.split()))\n",
    "print(df_train['Title Length'])\n",
    "\n",
    "# Modifying df_test for future use\n",
    "df_test['Title Length'] = df_test['Title'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a8cd83-049e-4827-88bb-1abc667f7a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Title length analysis\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df_train['Title Length'], bins=10)\n",
    "plt.title('Distribution of Title Lengths')\n",
    "plt.xlabel('Title Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b2092d-8b39-4af7-87d8-f68dae1ac8f6",
   "metadata": {},
   "source": [
    "Note that the distribution of our title lengths is right-skew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2596f239-a78f-42a0-a423-c89efab83248",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get TF IDF values as a dataframe\n",
    "\n",
    "tfidf_df = pd.DataFrame(train_title_features.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2648438c-becc-40db-a7d2-b8bb1a03fd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform matrix to array, flatten, and removes zeros\n",
    "\n",
    "tfidf_df = train_title_features.toarray().flatten()\n",
    "tfidf_df = tfidf_df[tfidf_df != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205b3bb2-d7a4-4997-91dc-e345bd828a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of non-zero TF-IDF Scores\n",
    "\n",
    "sns.histplot(tfidf_df, bins=10, kde=True)\n",
    "plt.xlabel(\"TF-IDF Score\")\n",
    "plt.ylabel(\"Number of Words\")\n",
    "plt.title(\"Distribution of TF-IDF Scores in the Corpus\")\n",
    "plt.xticks(rotation=45)  # Optional: Rotate x-axis labels for long feature names\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30cf47b-7428-4762-a44a-33451f69311d",
   "metadata": {},
   "source": [
    "Note that our TF IDF distribution is right skew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d716a021-67be-41b5-8911-5c1c18825a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_engine.outliers import Winsorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cf7fae-fe84-432d-af5f-b9537b9903f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot boxplot to find skewness\n",
    "\n",
    "sns.boxplot(df_train['Title Length'], orient='h')\n",
    "plt.xlabel(\"Title Length\")\n",
    "plt.title(\"Boxplot of Title Length\")  # Optional: Rotate x-axis labels for long feature names\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400d895e-0bd3-4d4c-9c0f-44d482f59bf0",
   "metadata": {},
   "source": [
    "Confirms previous image indicating right skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a261c00-1a44-45f9-ae10-d6369a59d128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Winsorize the text length to handle outliers\n",
    "\n",
    "capper = Winsorizer(capping_method='gaussian', tail='right', fold=2)\n",
    "capper.fit(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da52d1d-ccd4-4de8-b373-97da9f592f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "capper.right_tail_caps_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67976cd-7084-454b-a860-a473e0fe3be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_t = capper.transform(df_train)\n",
    "test_t = capper.transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66974e4b-4c06-41db-a76d-526c7ad7a487",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(train_t['Title Length'], orient='h')\n",
    "plt.xlabel(\"Title Length\")\n",
    "plt.title(\"Boxplot of Title Length\")  # Optional: Rotate x-axis labels for long feature names\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4c64f6-9f1e-4f33-aa48-d90f45e8807e",
   "metadata": {},
   "source": [
    "Outliers are no longer present in dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
